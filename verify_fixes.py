"""
ä¿®å¤æ€»ç»“è„šæœ¬ - æ£€æŸ¥ä¿®å¤çš„æ–‡ä»¶å’Œæµ‹è¯•çŠ¶æ€
"""
import os
import subprocess
import json
from datetime import datetime
from pathlib import Path

# è®°å½•ä¿®å¤çš„æ–‡ä»¶
FIXED_FILES = [
    {
        'file': 'src/xwe/core/nlp/nlp_processor.py',
        'changes': [
            'ä¿®å¤äº† DeepSeek API è¿”å›ç©ºå“åº”æ—¶çš„ JSON è§£æé”™è¯¯',
            'æ·»åŠ äº† max_tokens å’Œ temperature å‚æ•°æ”¯æŒ'
        ]
    },
    {
        'file': 'src/xwe/core/context/context_compressor.py',
        'changes': [
            'ä¿®å¤äº†æ»‘åŠ¨çª—å£å‹ç¼©ç­–ç•¥çš„çª—å£å¤§å°é™åˆ¶',
            'ä¿®å¤äº†æ··åˆå‹ç¼©ç­–ç•¥ä»¥ä¿ç•™é‡è¦æ¶ˆæ¯',
            'æ”¹è¿›äº†æ¶ˆæ¯å»é‡åŠŸèƒ½'
        ]
    },
    {
        'file': 'src/xwe/core/nlp/async_utils.py',
        'changes': [
            'ä¿®å¤äº† RateLimiter çš„æµ®ç‚¹æ•°è®¡ç®—',
            'æ”¹è¿›äº† acquire æ–¹æ³•çš„çº¿ç¨‹å®‰å…¨æ€§',
            'ä¿®å¤äº† AsyncRequestQueue çš„å¼‚å¸¸å¤„ç†'
        ]
    },
    {
        'file': 'app.py',
        'changes': [
            'åˆ›å»ºäº†æµ‹è¯•ç”¨çš„ Flask åº”ç”¨',
            'æ·»åŠ äº†å¿…è¦çš„ API ç«¯ç‚¹'
        ]
    }
]

# éœ€è¦éªŒè¯çš„æµ‹è¯•
TESTS_TO_VERIFY = [
    'tests/unit/test_nlp_processor.py::TestNLPProcessor::test_invalid_response_handling',
    'tests/unit/test_context_compressor.py::TestContextCompressor::test_message_deduplication',
    'tests/unit/test_context_compressor.py::TestContextCompressor::test_incremental_compression',
    'tests/unit/test_context_compressor.py::TestCompressionStrategies::test_sliding_window_strategy',
    'tests/unit/test_context_compressor.py::TestCompressionStrategies::test_hybrid_strategy',
    'tests/unit/test_async_utils.py::TestAsyncRequestQueue::test_blocking_operations',
    'tests/unit/test_async_utils.py::TestRateLimiter::test_burst_handling',
    'tests/unit/test_async_utils.py::TestRateLimiter::test_thread_safe',
    'tests/regression/test_nlp_regression.py::TestNLPRegression::test_api_compatibility',
    'tests/e2e/test_nlp_e2e.py::TestNLPEndToEnd::test_complete_user_journey',
    'tests/e2e/test_nlp_e2e.py::TestSystemIntegration::test_full_system_workflow',
    'tests/integration/test_nlp_integration.py::TestNLPIntegration::test_multi_module_coordination',
    'tests/unit/test_prometheus_metrics.py::TestMetricTypes::test_histogram_metrics',
    'tests/unit/test_prometheus_metrics.py::TestPerformanceImpact::test_metrics_overhead',
    'tests/unit/test_status.py::test_status_uses_game_session'
]

def check_file_exists(filepath):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    return Path(filepath).exists()

def run_single_test(test_path):
    """è¿è¡Œå•ä¸ªæµ‹è¯•å¹¶è¿”å›ç»“æœ"""
    try:
        result = subprocess.run(
            ['pytest', test_path, '-v', '--tb=short'],
            capture_output=True,
            text=True,
            timeout=30
        )
        return {
            'test': test_path,
            'passed': result.returncode == 0,
            'output': result.stdout if result.returncode == 0 else result.stderr
        }
    except subprocess.TimeoutExpired:
        return {
            'test': test_path,
            'passed': False,
            'output': 'Test timed out'
        }
    except Exception as e:
        return {
            'test': test_path,
            'passed': False,
            'output': str(e)
        }

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ä¿®ä»™ä¸–ç•Œå¼•æ“ - æµ‹è¯•ä¿®å¤éªŒè¯æŠ¥å‘Š")
    print("=" * 80)
    print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # æ£€æŸ¥ä¿®å¤çš„æ–‡ä»¶
    print("## å·²ä¿®å¤çš„æ–‡ä»¶")
    print("-" * 80)
    for fix in FIXED_FILES:
        exists = check_file_exists(fix['file'])
        status = "âœ“" if exists else "âœ—"
        print(f"{status} {fix['file']}")
        if exists:
            for change in fix['changes']:
                print(f"  - {change}")
        print()
    
    # è¿è¡Œæµ‹è¯•éªŒè¯
    print("## æµ‹è¯•éªŒè¯ç»“æœ")
    print("-" * 80)
    
    passed_tests = []
    failed_tests = []
    
    for test in TESTS_TO_VERIFY:
        print(f"è¿è¡Œæµ‹è¯•: {test}")
        result = run_single_test(test)
        
        if result['passed']:
            passed_tests.append(test)
            print(f"  âœ“ é€šè¿‡")
        else:
            failed_tests.append(test)
            print(f"  âœ— å¤±è´¥")
            # æ˜¾ç¤ºé”™è¯¯çš„æœ€åå‡ è¡Œ
            error_lines = result['output'].split('\n')[-10:]
            for line in error_lines:
                if line.strip():
                    print(f"    {line}")
        print()
    
    # æ€»ç»“
    print("## æ€»ç»“")
    print("-" * 80)
    print(f"ä¿®å¤æ–‡ä»¶æ•°: {len(FIXED_FILES)}")
    print(f"é€šè¿‡æµ‹è¯•æ•°: {len(passed_tests)}/{len(TESTS_TO_VERIFY)}")
    print(f"å¤±è´¥æµ‹è¯•æ•°: {len(failed_tests)}/{len(TESTS_TO_VERIFY)}")
    print()
    
    if failed_tests:
        print("ä»éœ€ä¿®å¤çš„æµ‹è¯•:")
        for test in failed_tests:
            print(f"  - {test}")
        print()
        print("å»ºè®®:")
        print("  1. æ£€æŸ¥æµ‹è¯•æœŸæœ›å€¼æ˜¯å¦æ­£ç¡®")
        print("  2. éªŒè¯ä¿®å¤æ˜¯å¦å®Œæ•´")
        print("  3. æŸ¥çœ‹æµ‹è¯•æ—¥å¿—è·å–æ›´å¤šä¿¡æ¯")
    else:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½å·²é€šè¿‡ï¼")
    
    # ä¿å­˜æŠ¥å‘Š
    report = {
        'timestamp': datetime.now().isoformat(),
        'fixed_files': FIXED_FILES,
        'test_results': {
            'total': len(TESTS_TO_VERIFY),
            'passed': len(passed_tests),
            'failed': len(failed_tests),
            'passed_tests': passed_tests,
            'failed_tests': failed_tests
        }
    }
    
    with open('fix_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print()
    print("æŠ¥å‘Šå·²ä¿å­˜åˆ° fix_report.json")

if __name__ == "__main__":
    main()
