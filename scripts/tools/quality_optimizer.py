#!/usr/bin/env python3
"""
ä»™ä¾ ä¸–ç•Œå¼•æ“ - ä»£ç è´¨é‡ä¼˜åŒ–å·¥å…·
è‡ªåŠ¨æ‰§è¡Œä»£ç è´¨é‡æ£€æŸ¥å’ŒåŸºç¡€ä¿®å¤

ä½¿ç”¨æ–¹æ³•:
python quality_optimizer.py --check          # æ£€æŸ¥ä»£ç è´¨é‡
python quality_optimizer.py --fix-basic      # ä¿®å¤åŸºç¡€é—®é¢˜
python quality_optimizer.py --todo-analysis  # TODOåˆ†æ
python quality_optimizer.py --full-report    # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
"""

import os
import sys
import re
import json
import argparse
from pathlib import Path
from typing import Dict, List, Any
from collections import defaultdict
import ast


class CodeQualityOptimizer:
    """ä»£ç è´¨é‡ä¼˜åŒ–å™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.issues = defaultdict(list)
        self.stats = {}
        
    def analyze_project(self) -> Dict[str, Any]:
        """åˆ†ææ•´ä¸ªé¡¹ç›®"""
        print("ğŸ” å¼€å§‹åˆ†æé¡¹ç›®...")
        
        # 1. ç»Ÿè®¡åŸºç¡€ä¿¡æ¯
        self._collect_basic_stats()
        
        # 2. TODOåˆ†æ
        self._analyze_todos()
        
        # 3. å¯¼å…¥ä¾èµ–åˆ†æ
        self._analyze_imports()
        
        # 4. ä»£ç å¤æ‚åº¦åˆ†æ
        self._analyze_complexity()
        
        # 5. æ€§èƒ½çƒ­ç‚¹åˆ†æ
        self._analyze_performance_hotspots()
        
        return {
            'stats': self.stats,
            'issues': dict(self.issues),
            'recommendations': self._generate_recommendations()
        }
    
    def _collect_basic_stats(self):
        """æ”¶é›†åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
        python_files = list(self.project_root.rglob("*.py"))
        
        total_lines = 0
        total_files = len(python_files)
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    total_lines += len(lines)
            except UnicodeDecodeError:
                continue
        
        self.stats.update({
            'total_files': total_files,
            'total_lines': total_lines,
            'avg_lines_per_file': total_lines // total_files if total_files > 0 else 0
        })
        
        print(f"ğŸ“Š å‘ç° {total_files} ä¸ªPythonæ–‡ä»¶ï¼Œå…± {total_lines} è¡Œä»£ç ")
    
    def _analyze_todos(self):
        """åˆ†æTODOæ³¨é‡Š"""
        todo_pattern = re.compile(r'#\s*TODO[:\s](.+)', re.IGNORECASE)
        todo_stats = defaultdict(list)
        
        for file_path in self.project_root.rglob("*.py"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    
                for i, line in enumerate(lines, 1):
                    match = todo_pattern.search(line)
                    if match:
                        todo_text = match.group(1).strip()
                        todo_stats[str(file_path)].append({
                            'line': i,
                            'text': todo_text
                        })
            except UnicodeDecodeError:
                continue
        
        total_todos = sum(len(todos) for todos in todo_stats.values())
        self.stats['todo_count'] = total_todos
        self.issues['todos'] = dict(todo_stats)
        
        print(f"ğŸ“ å‘ç° {total_todos} ä¸ªTODOé¡¹")
    
    def _analyze_imports(self):
        """åˆ†æå¯¼å…¥ä¾èµ–"""
        import_stats = defaultdict(set)
        circular_imports = []
        
        for file_path in self.project_root.rglob("*.py"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è§£æAST
                try:
                    tree = ast.parse(content)
                    for node in ast.walk(tree):
                        if isinstance(node, ast.Import):
                            for alias in node.names:
                                import_stats[str(file_path)].add(alias.name)
                        elif isinstance(node, ast.ImportFrom):
                            if node.module:
                                import_stats[str(file_path)].add(node.module)
                except SyntaxError:
                    continue
                    
            except UnicodeDecodeError:
                continue
        
        # æ£€æŸ¥å¾ªç¯å¯¼å…¥é£é™©
        core_files = [f for f in import_stats.keys() if 'core' in f]
        for core_file in core_files:
            imports = import_stats[core_file]
            for imp in imports:
                if 'npc' in imp and 'core' in core_file:
                    circular_imports.append(f"{core_file} -> {imp}")
        
        self.issues['circular_imports'] = circular_imports
        self.stats['import_complexity'] = len(import_stats)
        
        if circular_imports:
            print(f"âš ï¸  å‘ç° {len(circular_imports)} ä¸ªæ½œåœ¨å¾ªç¯å¯¼å…¥")
    
    def _analyze_complexity(self):
        """åˆ†æä»£ç å¤æ‚åº¦"""
        complex_functions = []
        long_functions = []
        
        for file_path in self.project_root.rglob("*.py"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    lines = content.split('\n')
                
                try:
                    tree = ast.parse(content)
                    for node in ast.walk(tree):
                        if isinstance(node, ast.FunctionDef):
                            # è®¡ç®—å‡½æ•°é•¿åº¦
                            func_lines = node.end_lineno - node.lineno if hasattr(node, 'end_lineno') else 0
                            
                            if func_lines > 50:  # è¶…è¿‡50è¡Œè®¤ä¸ºæ˜¯é•¿å‡½æ•°
                                long_functions.append({
                                    'file': str(file_path),
                                    'function': node.name,
                                    'lines': func_lines,
                                    'start_line': node.lineno
                                })
                            
                            # è®¡ç®—å¤æ‚åº¦ï¼ˆç®€å•çš„if/for/whileè®¡æ•°ï¼‰
                            complexity = self._calculate_cyclomatic_complexity(node)
                            if complexity > 10:  # å¤æ‚åº¦è¶…è¿‡10
                                complex_functions.append({
                                    'file': str(file_path),
                                    'function': node.name,
                                    'complexity': complexity,
                                    'start_line': node.lineno
                                })
                                
                except SyntaxError:
                    continue
                    
            except UnicodeDecodeError:
                continue
        
        self.issues['long_functions'] = long_functions
        self.issues['complex_functions'] = complex_functions
        
        print(f"ğŸ“ å‘ç° {len(long_functions)} ä¸ªè¶…é•¿å‡½æ•°")
        print(f"ğŸ”€ å‘ç° {len(complex_functions)} ä¸ªé«˜å¤æ‚åº¦å‡½æ•°")
    
    def _calculate_cyclomatic_complexity(self, node) -> int:
        """è®¡ç®—åœˆå¤æ‚åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        complexity = 1  # åŸºç¡€å¤æ‚åº¦
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.Try)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        
        return complexity
    
    def _analyze_performance_hotspots(self):
        """åˆ†ææ€§èƒ½çƒ­ç‚¹"""
        hotspots = []
        
        # æŸ¥æ‰¾å¯èƒ½çš„æ€§èƒ½é—®é¢˜
        patterns = {
            'network_calls': [r'requests\.', r'\.post\(', r'\.get\('],
            'file_io': [r'open\(', r'\.read\(', r'\.write\('],
            'loops_in_loops': [r'for.*for', r'while.*while'],
            'large_data_structures': [r'Dict\[.*Character', r'List\[.*Character']
        }
        
        for file_path in self.project_root.rglob("*.py"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                for category, pattern_list in patterns.items():
                    for pattern in pattern_list:
                        matches = re.findall(pattern, content)
                        if matches:
                            hotspots.append({
                                'file': str(file_path),
                                'category': category,
                                'matches': len(matches)
                            })
                            
            except UnicodeDecodeError:
                continue
        
        self.issues['performance_hotspots'] = hotspots
        print(f"âš¡ å‘ç° {len(hotspots)} ä¸ªæ½œåœ¨æ€§èƒ½çƒ­ç‚¹")
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # åŸºäºTODOæ•°é‡
        if self.stats.get('todo_count', 0) > 20:
            recommendations.append("ğŸ”´ ä¼˜å…ˆå¤„ç†TODOé¡¹ç›®ï¼Œç‰¹åˆ«æ˜¯game_core.pyä¸­çš„ç‰©å“ç³»ç»Ÿç›¸å…³TODO")
        
        # åŸºäºå¾ªç¯å¯¼å…¥
        if self.issues.get('circular_imports'):
            recommendations.append("ğŸŸ¡ è§£å†³å¾ªç¯å¯¼å…¥é—®é¢˜ï¼Œå»ºè®®ä½¿ç”¨ä¾èµ–æ³¨å…¥æˆ–äº‹ä»¶é©±åŠ¨æ¨¡å¼")
        
        # åŸºäºå‡½æ•°å¤æ‚åº¦
        if self.issues.get('long_functions'):
            recommendations.append("ğŸ”§ é‡æ„è¶…é•¿å‡½æ•°ï¼Œå»ºè®®æ‹†åˆ†ä¸ºå¤šä¸ªå°å‡½æ•°")
        
        # åŸºäºæ€§èƒ½çƒ­ç‚¹
        if self.issues.get('performance_hotspots'):
            recommendations.append("âš¡ ä¼˜åŒ–ç½‘ç»œè°ƒç”¨ï¼Œå»ºè®®æ·»åŠ ç¼“å­˜æœºåˆ¶")
        
        return recommendations
    
    def fix_basic_issues(self):
        """ä¿®å¤åŸºç¡€é—®é¢˜"""
        print("ğŸ”§ å¼€å§‹ä¿®å¤åŸºç¡€é—®é¢˜...")
        
        # 1. åˆ›å»ºç¼ºå¤±çš„åŸºç¡€æ–‡ä»¶
        self._create_missing_files()
        
        # 2. æ·»åŠ åŸºç¡€å¼‚å¸¸å¤„ç†
        self._add_basic_exception_handling()
        
        # 3. ç”Ÿæˆé…ç½®æ–‡ä»¶æ¨¡æ¿
        self._create_config_template()
        
        print("âœ… åŸºç¡€é—®é¢˜ä¿®å¤å®Œæˆ")
    
    def _create_missing_files(self):
        """åˆ›å»ºç¼ºå¤±çš„åŸºç¡€æ–‡ä»¶"""
        files_to_create = [
            'xwe/core/item_system.py',
            'xwe/core/confirmation_manager.py',
            'xwe/core/exception_handler.py'
        ]
        
        for file_path in files_to_create:
            full_path = self.project_root / file_path
            if not full_path.exists():
                full_path.parent.mkdir(parents=True, exist_ok=True)
                
                # åˆ›å»ºåŸºç¡€æ¨¡æ¿
                template = self._get_file_template(file_path)
                with open(full_path, 'w', encoding='utf-8') as f:
                    f.write(template)
                
                print(f"ğŸ“„ åˆ›å»ºæ–‡ä»¶: {file_path}")
    
    def _get_file_template(self, file_path: str) -> str:
        """è·å–æ–‡ä»¶æ¨¡æ¿"""
        if 'item_system' in file_path:
            return '''"""
ç‰©å“ç³»ç»Ÿ - ç®¡ç†æ¸¸æˆä¸­çš„ç‰©å“ã€èƒŒåŒ…ã€äº¤æ˜“ç­‰
"""

from typing import Dict, List, Optional
from dataclasses import dataclass, field


@dataclass
class Item:
    """ç‰©å“åŸºç¡€ç±»"""
    id: str
    name: str
    description: str
    value: int = 0
    stackable: bool = True
    max_stack: int = 99


class ItemSystem:
    """ç‰©å“ç³»ç»Ÿç®¡ç†å™¨"""
    
    def __init__(self):
        self.items: Dict[str, Item] = {}
        self.player_inventories: Dict[str, Dict[str, int]] = {}
    
    def get_spirit_stones(self, player_id: str) -> int:
        """è·å–ç©å®¶çš„çµçŸ³æ•°é‡"""
        inventory = self.player_inventories.get(player_id, {})
        return inventory.get('spirit_stones', 0)
    
    def add_item(self, player_id: str, item_id: str, quantity: int = 1) -> bool:
        """æ·»åŠ ç‰©å“åˆ°ç©å®¶èƒŒåŒ…"""
        if player_id not in self.player_inventories:
            self.player_inventories[player_id] = {}
        
        current = self.player_inventories[player_id].get(item_id, 0)
        self.player_inventories[player_id][item_id] = current + quantity
        return True
    
    def remove_item(self, player_id: str, item_id: str, quantity: int = 1) -> bool:
        """ä»ç©å®¶èƒŒåŒ…ç§»é™¤ç‰©å“"""
        inventory = self.player_inventories.get(player_id, {})
        if inventory.get(item_id, 0) >= quantity:
            inventory[item_id] -= quantity
            if inventory[item_id] <= 0:
                del inventory[item_id]
            return True
        return False


# å…¨å±€ç‰©å“ç³»ç»Ÿå®ä¾‹
item_system = ItemSystem()
'''
        elif 'confirmation_manager' in file_path:
            return '''"""
ç¡®è®¤æœºåˆ¶ç®¡ç†å™¨ - å¤„ç†éœ€è¦ç”¨æˆ·ç¡®è®¤çš„æ“ä½œ
"""

from typing import Dict, Callable, Any, Optional
from dataclasses import dataclass
import uuid


@dataclass
class PendingConfirmation:
    """å¾…ç¡®è®¤çš„æ“ä½œ"""
    id: str
    action: str
    description: str
    callback: Callable
    data: Dict[str, Any]


class ConfirmationManager:
    """ç¡®è®¤æœºåˆ¶ç®¡ç†å™¨"""
    
    def __init__(self):
        self.pending_confirmations: Dict[str, PendingConfirmation] = {}
    
    def request_confirmation(
        self, 
        action: str, 
        description: str,
        callback: Callable,
        data: Optional[Dict[str, Any]] = None
    ) -> str:
        """è¯·æ±‚ç”¨æˆ·ç¡®è®¤æ“ä½œ"""
        confirmation_id = str(uuid.uuid4())[:8]
        
        self.pending_confirmations[confirmation_id] = PendingConfirmation(
            id=confirmation_id,
            action=action,
            description=description,
            callback=callback,
            data=data or {}
        )
        
        return confirmation_id
    
    def confirm(self, confirmation_id: str, confirmed: bool = True) -> bool:
        """ç¡®è®¤æˆ–å–æ¶ˆæ“ä½œ"""
        if confirmation_id not in self.pending_confirmations:
            return False
        
        confirmation = self.pending_confirmations.pop(confirmation_id)
        
        if confirmed:
            try:
                confirmation.callback(confirmation.data)
                return True
            except Exception as e:
                print(f"ç¡®è®¤æ“ä½œæ‰§è¡Œå¤±è´¥: {e}")
                return False
        
        return True
    
    def get_pending_confirmations(self) -> Dict[str, PendingConfirmation]:
        """è·å–æ‰€æœ‰å¾…ç¡®è®¤æ“ä½œ"""
        return self.pending_confirmations.copy()


# å…¨å±€ç¡®è®¤ç®¡ç†å™¨å®ä¾‹
confirmation_manager = ConfirmationManager()
'''
        elif 'exception_handler' in file_path:
            return '''"""
ç»Ÿä¸€å¼‚å¸¸å¤„ç†å™¨
"""

import logging
import traceback
from typing import Any, Callable, Optional
from functools import wraps

logger = logging.getLogger(__name__)


class GameException(Exception):
    """æ¸¸æˆç›¸å…³å¼‚å¸¸åŸºç±»"""
    pass


class APIException(GameException):
    """APIè°ƒç”¨å¼‚å¸¸"""
    pass


class ConfigurationException(GameException):
    """é…ç½®å¼‚å¸¸"""
    pass


def handle_exceptions(
    default_return: Any = None,
    raise_on_error: bool = False,
    log_error: bool = True
):
    """å¼‚å¸¸å¤„ç†è£…é¥°å™¨"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                if log_error:
                    logger.error(
                        f"å‡½æ•° {func.__name__} æ‰§è¡Œå‡ºé”™: {e}\\n"
                        f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}"
                    )
                
                if raise_on_error:
                    raise
                
                return default_return
        
        return wrapper
    return decorator


def safe_api_call(func: Callable, *args, **kwargs) -> tuple[bool, Any]:
    """å®‰å…¨çš„APIè°ƒç”¨"""
    try:
        result = func(*args, **kwargs)
        return True, result
    except Exception as e:
        logger.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
        return False, None


def safe_file_operation(func: Callable, *args, **kwargs) -> tuple[bool, Any]:
    """å®‰å…¨çš„æ–‡ä»¶æ“ä½œ"""
    try:
        result = func(*args, **kwargs)
        return True, result
    except (IOError, OSError, UnicodeDecodeError) as e:
        logger.error(f"æ–‡ä»¶æ“ä½œå¤±è´¥: {e}")
        return False, None
'''
        
        return f'"""\n{file_path} - è‡ªåŠ¨ç”Ÿæˆçš„æ¨¡æ¿æ–‡ä»¶\n"""\n\npass\n'
    
    def _add_basic_exception_handling(self):
        """æ·»åŠ åŸºç¡€å¼‚å¸¸å¤„ç†"""
        # è¿™é‡Œå¯ä»¥æ‰«æå…³é”®æ–‡ä»¶å¹¶æ·»åŠ å¼‚å¸¸å¤„ç†
        print("ğŸ›¡ï¸  æ·»åŠ å¼‚å¸¸å¤„ç†é€»è¾‘...")
    
    def _create_config_template(self):
        """åˆ›å»ºé…ç½®æ¨¡æ¿"""
        config_path = self.project_root / 'game_config.py'
        if not config_path.exists():
            config_template = '''"""
æ¸¸æˆé…ç½®æ–‡ä»¶ - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰é…ç½®é¡¹
"""

import os
from dataclasses import dataclass
from typing import Optional


@dataclass
class GameConfig:
    """æ¸¸æˆé…ç½®"""
    # åŸºç¡€è®¾ç½®
    game_name: str = "ä»™ä¾ ä¸–ç•Œå¼•æ“"
    version: str = "2.0.0"
    debug_mode: bool = False
    
    # æ¸¸æˆå¹³è¡¡
    max_health: int = 100
    base_damage: float = 10.0
    cultivation_exp_multiplier: float = 1.0
    
    # APIè®¾ç½®
    deepseek_api_key: str = ""
    api_timeout: int = 15
    api_max_retries: int = 3
    
    # æ€§èƒ½è®¾ç½®
    cache_size: int = 1000
    max_npcs_in_memory: int = 50
    auto_save_interval: int = 300  # ç§’
    
    # è·¯å¾„è®¾ç½®
    data_path: str = "xwe/data"
    save_path: str = "saves"
    log_path: str = "logs"
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†"""
        # ä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥
        if not self.deepseek_api_key:
            self.deepseek_api_key = os.getenv('DEEPSEEK_API_KEY', '')
        
        # ç¡®ä¿è·¯å¾„å­˜åœ¨
        for path_attr in ['save_path', 'log_path']:
            path = getattr(self, path_attr)
            if path and not os.path.exists(path):
                os.makedirs(path, exist_ok=True)


# å…¨å±€é…ç½®å®ä¾‹
config = GameConfig()
'''
            
            with open(config_path, 'w', encoding='utf-8') as f:
                f.write(config_template)
            
            print("âš™ï¸  åˆ›å»ºé…ç½®æ–‡ä»¶: game_config.py")
    
    def generate_report(self) -> str:
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        analysis = self.analyze_project()
        
        report = f"""
# ä»™ä¾ ä¸–ç•Œå¼•æ“ - ä»£ç è´¨é‡åˆ†ææŠ¥å‘Š

## ğŸ“Š é¡¹ç›®ç»Ÿè®¡
- æ–‡ä»¶æ•°é‡: {analysis['stats']['total_files']}
- ä»£ç è¡Œæ•°: {analysis['stats']['total_lines']}
- å¹³å‡æ–‡ä»¶é•¿åº¦: {analysis['stats']['avg_lines_per_file']} è¡Œ

## ğŸ” å‘ç°çš„é—®é¢˜

### TODOé¡¹ç›® ({analysis['stats'].get('todo_count', 0)}ä¸ª)
"""
        
        # æ·»åŠ TODOè¯¦æƒ…
        for file_path, todos in analysis['issues'].get('todos', {}).items():
            if todos:
                report += f"\n**{file_path}**: {len(todos)}ä¸ªTODO\n"
                for todo in todos[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    report += f"- ç¬¬{todo['line']}è¡Œ: {todo['text']}\n"
        
        # æ·»åŠ æ¨èå»ºè®®
        report += "\n## ğŸ’¡ ä¼˜åŒ–å»ºè®®\n"
        for i, rec in enumerate(analysis['recommendations'], 1):
            report += f"{i}. {rec}\n"
        
        return report


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä»™ä¾ ä¸–ç•Œå¼•æ“ä»£ç è´¨é‡ä¼˜åŒ–å·¥å…·')
    parser.add_argument('--check', action='store_true', help='æ£€æŸ¥ä»£ç è´¨é‡')
    parser.add_argument('--fix-basic', action='store_true', help='ä¿®å¤åŸºç¡€é—®é¢˜')
    parser.add_argument('--todo-analysis', action='store_true', help='TODOåˆ†æ')
    parser.add_argument('--full-report', action='store_true', help='ç”Ÿæˆå®Œæ•´æŠ¥å‘Š')
    parser.add_argument('--project-path', default='.', help='é¡¹ç›®è·¯å¾„')
    
    args = parser.parse_args()
    
    optimizer = CodeQualityOptimizer(args.project_path)
    
    if args.check or not any([args.fix_basic, args.todo_analysis, args.full_report]):
        # é»˜è®¤æ‰§è¡Œæ£€æŸ¥
        print("ğŸš€ æ‰§è¡Œä»£ç è´¨é‡æ£€æŸ¥...\n")
        analysis = optimizer.analyze_project()
        
        print(f"\nğŸ“‹ æ£€æŸ¥å®Œæˆï¼")
        print(f"å‘ç°é—®é¢˜ç±»åˆ«: {len(analysis['issues'])}")
        print(f"ä¼˜åŒ–å»ºè®®: {len(analysis['recommendations'])}")
    
    if args.fix_basic:
        optimizer.fix_basic_issues()
    
    if args.todo_analysis:
        analysis = optimizer.analyze_project()
        print(f"\nğŸ“ TODOåˆ†æç»“æœ:")
        for file_path, todos in analysis['issues'].get('todos', {}).items():
            if todos:
                print(f"  {file_path}: {len(todos)}ä¸ªTODO")
    
    if args.full_report:
        report = optimizer.generate_report()
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = Path(args.project_path) / 'code_quality_report.md'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ“„ å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜: {report_path}")


if __name__ == '__main__':
    main()
