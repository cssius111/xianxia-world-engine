#!/usr/bin/env python
# @dev_only
"""
ç´§æ€¥ä¿®å¤ï¼šNLPæ¥å£ä¸ä¸€è‡´é—®é¢˜

é—®é¢˜ï¼šNLPProcessorç±»å®ç°çš„æ˜¯parse()æ–¹æ³•ï¼Œä½†æ‰€æœ‰è°ƒç”¨æ–¹éƒ½åœ¨ä½¿ç”¨process()æ–¹æ³•
è§£å†³æ–¹æ¡ˆï¼šç»Ÿä¸€æ¥å£ï¼Œä¿®å¤æ‰€æœ‰è°ƒç”¨ç‚¹
"""

import sys
from pathlib import Path
import re

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent.parent

def find_nlp_calls():
    """æŸ¥æ‰¾æ‰€æœ‰è°ƒç”¨NLP processæ–¹æ³•çš„æ–‡ä»¶"""
    problematic_files = []
    
    # æœç´¢æ‰€æœ‰Pythonæ–‡ä»¶
    for file_path in PROJECT_ROOT.rglob("*.py"):
        if ".git" in str(file_path) or "__pycache__" in str(file_path):
            continue
            
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æŸ¥æ‰¾è°ƒç”¨processæ–¹æ³•çš„åœ°æ–¹
            if re.search(r'nlp\.process\s*\(', content):
                problematic_files.append(file_path)
                print(f"âŒ å‘ç°é—®é¢˜è°ƒç”¨: {file_path.relative_to(PROJECT_ROOT)}")
                
        except Exception as e:
            pass
    
    return problematic_files

def fix_nlp_calls(files):
    """ä¿®å¤æ‰€æœ‰é”™è¯¯çš„è°ƒç”¨"""
    fixed_count = 0
    
    for file_path in files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ›¿æ¢processä¸ºparse
            new_content = re.sub(r'nlp\.process\s*\(', 'nlp.parse(', content)
            
            if new_content != content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                fixed_count += 1
                print(f"âœ… å·²ä¿®å¤: {file_path.relative_to(PROJECT_ROOT)}")
                
        except Exception as e:
            print(f"âš ï¸  ä¿®å¤å¤±è´¥ {file_path}: {e}")
    
    return fixed_count

def verify_nlp_implementation():
    """éªŒè¯NLPProcessorçš„å®é™…æ–¹æ³•å®ç°"""
    nlp_file = PROJECT_ROOT / "xwe/core/nlp/nlp_processor.py"
    
    if not nlp_file.exists():
        print("âŒ æ‰¾ä¸åˆ°NLPProcessoræ–‡ä»¶!")
        return False
    
    with open(nlp_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    has_parse = 'def parse(' in content
    has_process = 'def process(' in content
    
    print("\nğŸ“‹ NLPProcessoræ–¹æ³•æ£€æŸ¥:")
    print(f"  - parse() æ–¹æ³•: {'âœ… å­˜åœ¨' if has_parse else 'âŒ ä¸å­˜åœ¨'}")
    print(f"  - process() æ–¹æ³•: {'âœ… å­˜åœ¨' if has_process else 'âŒ ä¸å­˜åœ¨'}")
    
    return has_parse

def create_compatibility_wrapper():
    """ä¸ºNLPProcessoræ·»åŠ å…¼å®¹æ€§åŒ…è£…"""
    nlp_file = PROJECT_ROOT / "xwe/core/nlp/nlp_processor.py"
    
    with open(nlp_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰processæ–¹æ³•
    if 'def process(' in content:
        print("â„¹ï¸  processæ–¹æ³•å·²å­˜åœ¨ï¼Œè·³è¿‡æ·»åŠ åŒ…è£…å™¨")
        return
    
    # åœ¨ç±»çš„æœ€åæ·»åŠ å…¼å®¹æ€§æ–¹æ³•
    wrapper_code = '''
    def process(self, *args, **kwargs):
        """å…¼å®¹æ€§åŒ…è£…å™¨ï¼šå°†processè°ƒç”¨è½¬å‘åˆ°parseæ–¹æ³•"""
        import warnings
        warnings.warn(
            "process()æ–¹æ³•å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨parse()æ–¹æ³•ã€‚æ­¤åŒ…è£…å™¨å°†åœ¨æœªæ¥ç‰ˆæœ¬ä¸­ç§»é™¤ã€‚",
            DeprecationWarning,
            stacklevel=2
        )
        return self.parse(*args, **kwargs)
'''
    
    # æ‰¾åˆ°ç±»å®šä¹‰çš„ç»“æŸä½ç½®
    class_end = content.rfind('\nclass ')
    if class_end == -1:
        # å¦‚æœæ²¡æœ‰å…¶ä»–ç±»ï¼Œå°±åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ 
        new_content = content.rstrip() + '\n' + wrapper_code
    else:
        # åœ¨ä¸‹ä¸€ä¸ªç±»å®šä¹‰ä¹‹å‰æ’å…¥
        new_content = content[:class_end] + wrapper_code + '\n' + content[class_end:]
    
    with open(nlp_file, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    print("âœ… å·²æ·»åŠ å…¼å®¹æ€§åŒ…è£…å™¨")

def main():
    """ä¸»ä¿®å¤æµç¨‹"""
    print("ğŸ”§ NLPæ¥å£ä¿®å¤å·¥å…·")
    print("="*60)
    
    # 1. éªŒè¯NLPå®ç°
    print("\n1ï¸âƒ£ éªŒè¯NLPå®ç°...")
    if not verify_nlp_implementation():
        print("âŒ NLPProcessorå®ç°æœ‰é—®é¢˜!")
        return
    
    # 2. æŸ¥æ‰¾é—®é¢˜è°ƒç”¨
    print("\n2ï¸âƒ£ æŸ¥æ‰¾é”™è¯¯çš„process()è°ƒç”¨...")
    problematic_files = find_nlp_calls()
    
    if not problematic_files:
        print("âœ… æ²¡æœ‰å‘ç°é”™è¯¯çš„è°ƒç”¨!")
        return
    
    print(f"\nå‘ç° {len(problematic_files)} ä¸ªæ–‡ä»¶å­˜åœ¨é—®é¢˜")
    
    # 3. è¯¢é—®ä¿®å¤æ–¹å¼
    print("\n3ï¸âƒ£ é€‰æ‹©ä¿®å¤æ–¹å¼:")
    print("1. ä¿®æ”¹æ‰€æœ‰è°ƒç”¨ç‚¹ï¼Œå°†processæ”¹ä¸ºparseï¼ˆæ¨èï¼‰")
    print("2. ä¸ºNLPProcessoræ·»åŠ processå…¼å®¹æ–¹æ³•")
    print("3. ä¸¤ç§æ–¹å¼éƒ½æ‰§è¡Œï¼ˆæœ€å®‰å…¨ï¼‰")
    
    choice = input("\nè¯·é€‰æ‹© (1-3): ").strip()
    
    if choice == '1' or choice == '3':
        print("\nğŸ”„ ä¿®å¤è°ƒç”¨ç‚¹...")
        fixed = fix_nlp_calls(problematic_files)
        print(f"âœ… æˆåŠŸä¿®å¤ {fixed} ä¸ªæ–‡ä»¶")
    
    if choice == '2' or choice == '3':
        print("\nğŸ”„ æ·»åŠ å…¼å®¹æ€§åŒ…è£…...")
        create_compatibility_wrapper()
    
    # 4. éªŒè¯ä¿®å¤
    print("\n4ï¸âƒ£ éªŒè¯ä¿®å¤ç»“æœ...")
    remaining = find_nlp_calls()
    if not remaining:
        print("âœ… æ‰€æœ‰é—®é¢˜å·²ä¿®å¤!")
    else:
        print(f"âš ï¸  ä»æœ‰ {len(remaining)} ä¸ªæ–‡ä»¶å­˜åœ¨é—®é¢˜")
    
    print("\nâœ¨ ä¿®å¤å®Œæˆ!")
    print("\nå»ºè®®è¿è¡Œä»¥ä¸‹å‘½ä»¤æµ‹è¯•:")
    print("  python scripts/test_nlp.py")
    print("  python main_menu.py")

if __name__ == "__main__":
    main()
