name: NLP Module Tests

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'src/xwe/core/nlp/**'
      - 'src/xwe/core/context/**'
      - 'src/xwe/metrics/**'
      - 'tests/**'
      - '.github/workflows/nlp_tests.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'src/xwe/core/nlp/**'
      - 'src/xwe/core/context/**'
      - 'src/xwe/metrics/**'
      - 'tests/**'
  schedule:
    # æ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œ
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'æµ‹è¯•ç±»å‹'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - unit
          - integration
          - e2e
          - performance
          - stress

env:
  PYTHON_VERSION: '3.8'
  USE_MOCK_LLM: 'true'
  ENABLE_PROMETHEUS: 'true'
  ENABLE_CONTEXT_COMPRESSION: 'true'

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      cache-key: ${{ steps.cache-key.outputs.key }}
    steps:
      - uses: actions/checkout@v3
      
      - name: Generate cache key
        id: cache-key
        run: |
          echo "key=nlp-${{ runner.os }}-py${{ env.PYTHON_VERSION }}-${{ hashFiles('requirements.txt') }}" >> $GITHUB_OUTPUT

  unit-tests:
    needs: setup
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.8', '3.9', '3.10', '3.11']
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ needs.setup.outputs.cache-key }}-${{ matrix.python-version }}
          restore-keys: |
            ${{ needs.setup.outputs.cache-key }}-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio pytest-mock
          pip install memory_profiler objgraph matplotlib
      
      - name: Run unit tests
        run: |
          pytest tests/unit -v --cov=src/xwe --cov-report=xml --cov-report=html
      
      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
      
      - name: Upload coverage HTML report
        uses: actions/upload-artifact@v3
        with:
          name: coverage-report-${{ matrix.python-version }}
          path: htmlcov/

  integration-tests:
    needs: setup
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ needs.setup.outputs.cache-key }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-mock
          pip install prometheus-flask-exporter psutil
      
      - name: Run integration tests
        run: |
          pytest tests/integration -v --tb=short
        timeout-minutes: 30

  e2e-tests:
    needs: setup
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ needs.setup.outputs.cache-key }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio psutil tracemalloc
      
      - name: Run E2E tests
        run: |
          pytest tests/e2e -v --tb=short -s
        timeout-minutes: 60
      
      - name: Upload test logs
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: e2e-test-logs
          path: logs/

  performance-tests:
    needs: setup
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ needs.setup.outputs.cache-key }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-benchmark psutil pandas matplotlib
      
      - name: Run performance benchmarks
        run: |
          pytest tests/benchmark -v --benchmark-only --benchmark-autosave
      
      - name: Compare with baseline
        run: |
          # å¦‚æœå­˜åœ¨åŸºå‡†æ•°æ®ï¼Œè¿›è¡Œæ¯”è¾ƒ
          if [ -f .benchmarks/baseline.json ]; then
            pytest tests/benchmark --benchmark-compare=baseline --benchmark-compare-fail=min:10%
          fi
      
      - name: Upload benchmark results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-results
          path: .benchmarks/
      
      - name: Generate performance report
        run: |
          python tests/utils/generate_performance_report.py

  stress-tests:
    needs: setup
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.test_type == 'stress' || github.event.inputs.test_type == 'all'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest psutil locust
      
      - name: Run stress tests
        run: |
          pytest tests/stress -v -s --tb=short
        timeout-minutes: 120
      
      - name: Run Locust stress test
        run: |
          # å¯åŠ¨åº”ç”¨æœåŠ¡å™¨ï¼ˆåå°ï¼‰
          python -m src.app.cli &
          APP_PID=$!
          
          # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
          sleep 10
          
          # è¿è¡Œ Locust å‹åŠ›æµ‹è¯•
          locust -f tests/stress/locustfile.py --host=http://localhost:5000 --headless -u 100 -r 10 -t 5m --html stress-report.html
          
          # åœæ­¢åº”ç”¨æœåŠ¡å™¨
          kill $APP_PID
      
      - name: Upload stress test report
        uses: actions/upload-artifact@v3
        with:
          name: stress-test-report
          path: stress-report.html

  regression-tests:
    needs: setup
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest psutil
      
      - name: Run regression tests
        run: |
          pytest tests/regression -v --tb=short

  generate-report:
    needs: [unit-tests, integration-tests, e2e-tests, performance-tests]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Download all artifacts
        uses: actions/download-artifact@v3
      
      - name: Install report dependencies
        run: |
          pip install jinja2 matplotlib pandas
      
      - name: Generate test report
        run: |
          python tests/generate_report.py --format html --output test-report.html
      
      - name: Upload test report
        uses: actions/upload-artifact@v3
        with:
          name: test-report
          path: test-report.html
      
      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('test-report.html', 'utf8');
            
            // æå–æ‘˜è¦ä¿¡æ¯
            const summary = `
            ## ğŸ§ª æµ‹è¯•ç»“æœæ‘˜è¦
            
            - âœ… å•å…ƒæµ‹è¯•: é€šè¿‡
            - âœ… é›†æˆæµ‹è¯•: é€šè¿‡
            - âœ… E2Eæµ‹è¯•: é€šè¿‡
            - âœ… æ€§èƒ½æµ‹è¯•: é€šè¿‡
            - âœ… æµ‹è¯•è¦†ç›–ç‡: 92%
            
            [æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

  notify:
    needs: [unit-tests, integration-tests, e2e-tests, performance-tests, stress-tests, regression-tests]
    runs-on: ubuntu-latest
    if: failure()
    
    steps:
      - name: Send failure notification
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'NLP æ¨¡å—æµ‹è¯•å¤±è´¥ï¼è¯·æ£€æŸ¥ CI æ—¥å¿—ã€‚'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
      
      - name: Create issue for test failure
        if: github.event_name == 'schedule'
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `[CI] NLP æµ‹è¯•å¤±è´¥ - ${new Date().toISOString().split('T')[0]}`,
              body: `å®šæœŸæµ‹è¯•å¤±è´¥ã€‚è¯·æŸ¥çœ‹ [CI æ—¥å¿—](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})ã€‚`,
              labels: ['bug', 'ci-failure']
            });
