"""
å›å½’æµ‹è¯•å¥—ä»¶
ç¡®ä¿ä¿®å¤çš„é—®é¢˜ä¸ä¼šå†æ¬¡å‡ºç°
"""

import pytest
import json
import os
import sys
import time
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(PROJECT_ROOT / "src"))

# é…ç½®æµ‹è¯•ç¯å¢ƒ
os.environ['USE_MOCK_LLM'] = 'true'
os.environ['ENABLE_PROMETHEUS'] = 'true'


class TestNLPRegression:
    """NLP å›å½’æµ‹è¯•"""
    
    @pytest.fixture
    def nlp_processor(self):
        """åˆ›å»º NLP å¤„ç†å™¨"""
        from xwe.core.nlp.nlp_processor import NLPProcessor
        return NLPProcessor()
    
    def test_issue_001_empty_context_crash(self, nlp_processor):
        """
        é—®é¢˜ #001: ç©ºä¸Šä¸‹æ–‡å¯¼è‡´å´©æºƒ
        ä¿®å¤æ—¥æœŸ: 2024-01-15
        """
        # ä¹‹å‰ä¼šå´©æºƒçš„æƒ…å†µ
        empty_context = []
        result = nlp_processor.process("æµ‹è¯•å‘½ä»¤", empty_context)
        
        # éªŒè¯ä¸ä¼šå´©æºƒä¸”è¿”å›æœ‰æ•ˆç»“æœ
        assert result is not None
        assert 'normalized_command' in result
    
    def test_issue_002_unicode_handling(self, nlp_processor):
        """
        é—®é¢˜ #002: Unicode å­—ç¬¦å¤„ç†é”™è¯¯
        ä¿®å¤æ—¥æœŸ: 2024-01-20
        """
        # å„ç§ Unicode æµ‹è¯•ç”¨ä¾‹
        unicode_commands = [
            "ä½¿ç”¨é“å…·ã€Œç ´å¤©å‰‘ã€",
            "å‰å¾€ã€ä»™çµç§˜å¢ƒã€‘",
            "ä¸NPCã€Œæç™½ã€å¯¹è¯",
            "ä½¿ç”¨æŠ€èƒ½ï¼šç ´å¤©æ–©ï¼",
            "æŸ¥çœ‹ç‰©å“ï¼ˆç¨€æœ‰ï¼‰",
            "æ¢ç´¢åŒºåŸŸâ†’ä¸œæ–¹",
            "ä½¿ç”¨è¡¨æƒ…ğŸ˜Šæˆ˜æ–—ğŸ’ª",
            "ä¸­æ–‡ã€Englishã€æ—¥æœ¬èªæ··åˆ"
        ]
        
        for cmd in unicode_commands:
            result = nlp_processor.process(cmd)
            assert result is not None
            # ç¡®ä¿æ²¡æœ‰ç¼–ç é”™è¯¯
            assert isinstance(result.get('normalized_command', ''), str)
    
    def test_issue_003_memory_leak_in_context(self, nlp_processor):
        """
        é—®é¢˜ #003: ä¸Šä¸‹æ–‡ç´¯ç§¯å¯¼è‡´å†…å­˜æ³„æ¼
        ä¿®å¤æ—¥æœŸ: 2024-01-25
        """
        import psutil
        import gc
        
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # æ¨¡æ‹Ÿé•¿æ—¶é—´è¿è¡Œ
        context = []
        for i in range(1000):
            result = nlp_processor.process(f"å‘½ä»¤ {i}", context)
            context.append({
                'round': i,
                'command': f"å‘½ä»¤ {i}",
                'result': result
            })
            
            # æ¯100è½®æ£€æŸ¥å†…å­˜
            if i % 100 == 0:
                gc.collect()
                current_memory = process.memory_info().rss / 1024 / 1024
                memory_growth = current_memory - initial_memory
                
                # å†…å­˜å¢é•¿åº”è¯¥æ˜¯æœ‰é™çš„
                assert memory_growth < 100, f"å†…å­˜å¢é•¿è¿‡å¤§: {memory_growth}MB"
    
    def test_issue_004_concurrent_access_race_condition(self):
        """
        é—®é¢˜ #004: å¹¶å‘è®¿é—®ç«æ€æ¡ä»¶
        ä¿®å¤æ—¥æœŸ: 2024-02-01
        """
        from xwe.core.nlp.nlp_processor import NLPProcessor
        import threading
        
        # å…±äº«çš„å¤„ç†å™¨å®ä¾‹
        processor = NLPProcessor()
        results = []
        errors = []
        
        def worker(worker_id):
            try:
                for i in range(10):
                    result = processor.process(f"å¹¶å‘æµ‹è¯• {worker_id}-{i}")
                    results.append(result)
            except Exception as e:
                errors.append(str(e))
        
        # å¯åŠ¨å¤šä¸ªçº¿ç¨‹
        threads = []
        for i in range(10):
            t = threading.Thread(target=worker, args=(i,))
            t.start()
            threads.append(t)
        
        # ç­‰å¾…å®Œæˆ
        for t in threads:
            t.join()
        
        # éªŒè¯æ²¡æœ‰é”™è¯¯ä¸”æ‰€æœ‰è¯·æ±‚éƒ½å¤„ç†äº†
        assert len(errors) == 0, f"å¹¶å‘é”™è¯¯: {errors}"
        assert len(results) == 100  # 10çº¿ç¨‹ * 10è¯·æ±‚
    
    def test_issue_005_api_timeout_handling(self):
        """
        é—®é¢˜ #005: API è¶…æ—¶å¤„ç†ä¸å½“
        ä¿®å¤æ—¥æœŸ: 2024-02-10
        """
        from xwe.core.nlp.llm_client import LLMClient
        
        # è®¾ç½®æçŸ­çš„è¶…æ—¶
        original_timeout = os.environ.get('LLM_TIMEOUT', '30')
        os.environ['LLM_TIMEOUT'] = '0.001'
        
        try:
            client = LLMClient(timeout=0.001)
            
            # åº”è¯¥ä¼˜é›…å¤„ç†è¶…æ—¶
            result = client.chat("è¶…æ—¶æµ‹è¯•")
            
            # Mock æ¨¡å¼ä¸‹åº”è¯¥æ­£å¸¸è¿”å›
            assert result is not None
            
        finally:
            os.environ['LLM_TIMEOUT'] = original_timeout
            if hasattr(client, 'cleanup'):
                client.cleanup()
    
    def test_issue_006_context_compression_data_loss(self):
        """
        é—®é¢˜ #006: ä¸Šä¸‹æ–‡å‹ç¼©å¯¼è‡´æ•°æ®ä¸¢å¤±
        ä¿®å¤æ—¥æœŸ: 2024-02-15
        """
        from xwe.core.context.context_compressor import ContextCompressor
        
        compressor = ContextCompressor()
        
        # åˆ›å»ºåŒ…å«é‡è¦ä¿¡æ¯çš„ä¸Šä¸‹æ–‡
        important_context = [
            {"role": "system", "content": "é‡è¦ç³»ç»Ÿæ¶ˆæ¯"},
            {"role": "user", "content": "è®¾ç½®ç©å®¶åç§°ä¸ºï¼šç‹¬å­¤æ±‚è´¥"},
            {"role": "assistant", "content": "ç©å®¶åç§°å·²è®¾ç½®"},
            {"role": "user", "content": "è®°ä½å¯†ç ï¼šXYZ123"},
            {"role": "assistant", "content": "å·²è®°å½•"},
        ]
        
        # æ·»åŠ å¤§é‡å¡«å……å†…å®¹
        for i in range(100):
            important_context.extend([
                {"role": "user", "content": f"å¡«å……æ¶ˆæ¯ {i}"},
                {"role": "assistant", "content": f"å›å¤ {i}"},
            ])
        
        # å‹ç¼©
        compressed = compressor.compress(important_context)
        
        # éªŒè¯é‡è¦ä¿¡æ¯è¢«ä¿ç•™
        compressed_str = json.dumps(compressed, ensure_ascii=False)
        assert "ç‹¬å­¤æ±‚è´¥" in compressed_str or "ç©å®¶åç§°" in compressed_str
        assert "ç³»ç»Ÿæ¶ˆæ¯" in compressed_str or "system" in compressed_str
    
    def test_issue_007_special_characters_in_commands(self, nlp_processor):
        """
        é—®é¢˜ #007: ç‰¹æ®Šå­—ç¬¦å¯¼è‡´è§£æé”™è¯¯
        ä¿®å¤æ—¥æœŸ: 2024-02-20
        """
        special_commands = [
            "ä½¿ç”¨æŠ€èƒ½[ç ´å¤©æ–©]",
            "å‰å¾€<å¹½å†¥è°·>",
            "ä¸NPC{å•†äºº}å¯¹è¯",
            "æŸ¥çœ‹ç‰©å“|ç¨€æœ‰|",
            "æ‰§è¡Œå‘½ä»¤:æ¢ç´¢;æˆ˜æ–—;é€ƒè·‘",
            "ä½¿ç”¨é“å…·(å›è¡€ä¸¹*3)",
            "æŠ€èƒ½è¿æ‹›A->B->C",
            "æŸ¥è¯¢ä»·æ ¼$1000",
            "ä½¿ç”¨ç»„åˆé”®^C",
            "è¾“å…¥å¯†ç #abc123!"
        ]
        
        for cmd in special_commands:
            result = nlp_processor.process(cmd)
            assert result is not None
            assert 'error' not in result or result.get('error') is None
    
    def test_issue_008_performance_degradation(self, nlp_processor):
        """
        é—®é¢˜ #008: æ€§èƒ½é€€åŒ–
        ä¿®å¤æ—¥æœŸ: 2024-02-25
        åŸºå‡†: å¹³å‡å¤„ç†æ—¶é—´ < 100ms
        """
        import statistics
        
        # é¢„çƒ­
        for _ in range(5):
            nlp_processor.process("é¢„çƒ­å‘½ä»¤")
        
        # æ€§èƒ½æµ‹è¯•
        processing_times = []
        test_commands = ["æ¢ç´¢", "æˆ˜æ–—", "æŸ¥çœ‹çŠ¶æ€", "ä½¿ç”¨ç‰©å“", "å¯¹è¯"]
        
        for _ in range(20):
            for cmd in test_commands:
                start_time = time.time()
                nlp_processor.process(cmd)
                duration = time.time() - start_time
                processing_times.append(duration)
        
        # è®¡ç®—ç»Ÿè®¡
        avg_time = statistics.mean(processing_times) * 1000  # è½¬æ¢ä¸ºms
        p95_time = sorted(processing_times)[int(len(processing_times) * 0.95)] * 1000
        
        print(f"\næ€§èƒ½ç»Ÿè®¡:")
        print(f"  å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.2f}ms")
        print(f"  P95å¤„ç†æ—¶é—´: {p95_time:.2f}ms")
        
        # éªŒè¯æ€§èƒ½åŸºå‡†
        assert avg_time < 100, f"å¹³å‡å¤„ç†æ—¶é—´è¶…è¿‡åŸºå‡†: {avg_time}ms > 100ms"
        assert p95_time < 200, f"P95å¤„ç†æ—¶é—´è¶…è¿‡åŸºå‡†: {p95_time}ms > 200ms"
    
    def test_api_compatibility(self):
        """æµ‹è¯• API å…¼å®¹æ€§"""
        from xwe.core.nlp.nlp_processor import NLPProcessor
        
        processor = NLPProcessor()
        
        # æµ‹è¯• v1 API æ ¼å¼
        v1_result = processor.process("æµ‹è¯•å‘½ä»¤")
        assert 'normalized_command' in v1_result
        assert 'intent' in v1_result
        
        # æµ‹è¯•å¸¦ä¸Šä¸‹æ–‡çš„è°ƒç”¨
        context = [{"role": "user", "content": "ä¹‹å‰çš„å‘½ä»¤"}]
        v1_with_context = processor.process("æ–°å‘½ä»¤", context)
        assert v1_with_context is not None
        
        # æµ‹è¯•å¯é€‰å‚æ•°
        v1_with_options = processor.process(
            "æµ‹è¯•å‘½ä»¤",
            context=[],
            max_tokens=256,
            temperature=0.7
        )
        assert v1_with_options is not None
    
    def test_configuration_compatibility(self):
        """æµ‹è¯•é…ç½®å…¼å®¹æ€§"""
        # æµ‹è¯•æ—§é…ç½®æ ¼å¼
        old_configs = [
            {'NLP_MODEL': 'gpt-3.5'},  # æ—§é…ç½®å
            {'ENABLE_NLP': 'true'},     # æ—§å¼€å…³
            {'NLP_CACHE_SIZE': '1000'}, # æ—§ç¼“å­˜é…ç½®
        ]
        
        for config in old_configs:
            # è®¾ç½®æ—§é…ç½®
            for key, value in config.items():
                os.environ[key] = value
            
            # ç¡®ä¿ç³»ç»Ÿä»èƒ½æ­£å¸¸å·¥ä½œ
            from xwe.core.nlp.nlp_processor import NLPProcessor
            processor = NLPProcessor()
            result = processor.process("å…¼å®¹æ€§æµ‹è¯•")
            assert result is not None
    
    def test_performance_regression_check(self):
        """æ€§èƒ½å›å½’æ£€æŸ¥"""
        # åŠ è½½å†å²æ€§èƒ½æ•°æ®
        benchmark_file = PROJECT_ROOT / 'tests' / 'benchmarks' / 'nlp_performance.json'
        
        current_benchmark = {
            'date': datetime.now().isoformat(),
            'metrics': {
                'avg_response_time_ms': 0,
                'p95_response_time_ms': 0,
                'compression_ratio': 0,
                'memory_usage_mb': 0
            }
        }
        
        # è¿è¡Œæ€§èƒ½æµ‹è¯•
        from xwe.core.nlp.nlp_processor import NLPProcessor
        from xwe.core.context.context_compressor import ContextCompressor
        import psutil
        
        processor = NLPProcessor()
        compressor = ContextCompressor()
        
        # æµ‹è¯•å“åº”æ—¶é—´
        times = []
        for _ in range(50):
            start = time.time()
            processor.process("æ€§èƒ½æµ‹è¯•å‘½ä»¤")
            times.append(time.time() - start)
        
        current_benchmark['metrics']['avg_response_time_ms'] = sum(times) / len(times) * 1000
        current_benchmark['metrics']['p95_response_time_ms'] = sorted(times)[int(len(times) * 0.95)] * 1000
        
        # æµ‹è¯•å‹ç¼©ç‡
        test_context = [{"content": f"æ¶ˆæ¯{i}" * 10} for i in range(100)]
        original_size = len(json.dumps(test_context))
        compressed_size = len(json.dumps(compressor.compress(test_context)))
        current_benchmark['metrics']['compression_ratio'] = compressed_size / original_size
        
        # æµ‹è¯•å†…å­˜ä½¿ç”¨
        process = psutil.Process()
        current_benchmark['metrics']['memory_usage_mb'] = process.memory_info().rss / 1024 / 1024
        
        # ä¿å­˜å½“å‰åŸºå‡†
        benchmark_file.parent.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½å†å²æ•°æ®
        historical_benchmarks = []
        if benchmark_file.exists():
            with open(benchmark_file, 'r') as f:
                historical_benchmarks = json.load(f)
        
        # æ·»åŠ å½“å‰ç»“æœ
        historical_benchmarks.append(current_benchmark)
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        with open(benchmark_file, 'w') as f:
            json.dump(historical_benchmarks[-10:], f, indent=2)  # åªä¿ç•™æœ€è¿‘10æ¬¡
        
        # å¦‚æœæœ‰å†å²æ•°æ®ï¼Œè¿›è¡Œæ¯”è¾ƒ
        if len(historical_benchmarks) > 1:
            previous = historical_benchmarks[-2]['metrics']
            current = current_benchmark['metrics']
            
            # æ£€æŸ¥æ€§èƒ½é€€åŒ–ï¼ˆå…è®¸10%çš„æ³¢åŠ¨ï¼‰
            if previous['avg_response_time_ms'] > 0:
                performance_change = (current['avg_response_time_ms'] - previous['avg_response_time_ms']) / previous['avg_response_time_ms']
                assert performance_change < 0.1, f"æ€§èƒ½é€€åŒ–: {performance_change * 100:.1f}%"
        
        print(f"\nå½“å‰æ€§èƒ½åŸºå‡†:")
        print(f"  å¹³å‡å“åº”: {current_benchmark['metrics']['avg_response_time_ms']:.2f}ms")
        print(f"  P95å“åº”: {current_benchmark['metrics']['p95_response_time_ms']:.2f}ms")
        print(f"  å‹ç¼©ç‡: {current_benchmark['metrics']['compression_ratio']:.2%}")
        print(f"  å†…å­˜ä½¿ç”¨: {current_benchmark['metrics']['memory_usage_mb']:.2f}MB")


class RegressionTestRunner:
    """å›å½’æµ‹è¯•è¿è¡Œå™¨"""
    
    @staticmethod
    def run_all_regression_tests():
        """è¿è¡Œæ‰€æœ‰å›å½’æµ‹è¯•"""
        print("å¼€å§‹è¿è¡Œ NLP å›å½’æµ‹è¯•å¥—ä»¶...")
        print("=" * 60)
        
        # è¿è¡Œæµ‹è¯•
        pytest.main([
            __file__,
            "-v",
            "--tb=short",
            "-k", "test_issue"  # åªè¿è¡Œé—®é¢˜ç›¸å…³çš„æµ‹è¯•
        ])
        
        print("\nè¿è¡Œå…¼å®¹æ€§æµ‹è¯•...")
        pytest.main([
            __file__,
            "-v",
            "--tb=short",
            "-k", "compatibility"
        ])


if __name__ == "__main__":
    RegressionTestRunner.run_all_regression_tests()
