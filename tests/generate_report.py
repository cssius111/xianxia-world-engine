"""
æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨
æ±‡æ€»æ‰€æœ‰æµ‹è¯•ç»“æœå¹¶ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
"""

import json
import time
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import matplotlib.pyplot as plt
import pandas as pd
from jinja2 import Template


class TestReportGenerator:
    """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.test_results = {
            'summary': {
                'total_tests': 0,
                'passed': 0,
                'failed': 0,
                'skipped': 0,
                'duration': 0,
                'timestamp': datetime.now().isoformat()
            },
            'unit_tests': [],
            'integration_tests': [],
            'e2e_tests': [],
            'performance_tests': [],
            'stress_tests': [],
            'regression_tests': [],
            'coverage': {},
            'metrics': {}
        }
    
    def collect_test_results(self, test_dir: Path):
        """æ”¶é›†æµ‹è¯•ç»“æœ"""
        # æ”¶é›† pytest ç»“æœ
        pytest_results = test_dir / '.pytest_cache' / 'v' / 'cache' / 'lastfailed'
        if pytest_results.exists():
            with open(pytest_results, 'r') as f:
                failed_tests = json.load(f)
                self.test_results['summary']['failed'] += len(failed_tests)
        
        # æ”¶é›†è¦†ç›–ç‡æ•°æ®
        coverage_file = test_dir / 'coverage.json'
        if coverage_file.exists():
            with open(coverage_file, 'r') as f:
                self.test_results['coverage'] = json.load(f)
        
        # æ”¶é›†æ€§èƒ½æ•°æ®
        benchmark_dir = test_dir / '.benchmarks'
        if benchmark_dir.exists():
            for benchmark_file in benchmark_dir.glob('*.json'):
                with open(benchmark_file, 'r') as f:
                    benchmark_data = json.load(f)
                    self.test_results['performance_tests'].extend(
                        benchmark_data.get('benchmarks', [])
                    )
        
        # æ”¶é›†å„ç±»æµ‹è¯•ç»“æœ
        self._collect_junit_results(test_dir)
        self._collect_custom_results(test_dir)
    
    def _collect_junit_results(self, test_dir: Path):
        """æ”¶é›† JUnit æ ¼å¼çš„æµ‹è¯•ç»“æœ"""
        import xml.etree.ElementTree as ET
        
        for junit_file in test_dir.glob('**/junit*.xml'):
            try:
                tree = ET.parse(junit_file)
                root = tree.getroot()
                
                for testsuite in root.findall('.//testsuite'):
                    suite_name = testsuite.get('name', 'unknown')
                    
                    for testcase in testsuite.findall('.//testcase'):
                        test_result = {
                            'name': testcase.get('name'),
                            'classname': testcase.get('classname'),
                            'time': float(testcase.get('time', 0)),
                            'status': 'passed'
                        }
                        
                        # æ£€æŸ¥å¤±è´¥
                        if testcase.find('.//failure') is not None:
                            test_result['status'] = 'failed'
                            test_result['message'] = testcase.find('.//failure').get('message', '')
                        
                        # æ£€æŸ¥è·³è¿‡
                        elif testcase.find('.//skipped') is not None:
                            test_result['status'] = 'skipped'
                            test_result['message'] = testcase.find('.//skipped').get('message', '')
                        
                        # åˆ†ç±»å­˜å‚¨
                        if 'unit' in suite_name.lower():
                            self.test_results['unit_tests'].append(test_result)
                        elif 'integration' in suite_name.lower():
                            self.test_results['integration_tests'].append(test_result)
                        elif 'e2e' in suite_name.lower():
                            self.test_results['e2e_tests'].append(test_result)
                        elif 'regression' in suite_name.lower():
                            self.test_results['regression_tests'].append(test_result)
                        
                        # æ›´æ–°ç»Ÿè®¡
                        self.test_results['summary']['total_tests'] += 1
                        if test_result['status'] == 'passed':
                            self.test_results['summary']['passed'] += 1
                        elif test_result['status'] == 'failed':
                            self.test_results['summary']['failed'] += 1
                        else:
                            self.test_results['summary']['skipped'] += 1
                        
                        self.test_results['summary']['duration'] += test_result['time']
            
            except Exception as e:
                print(f"è§£æ JUnit æ–‡ä»¶å¤±è´¥ {junit_file}: {e}")
    
    def _collect_custom_results(self, test_dir: Path):
        """æ”¶é›†è‡ªå®šä¹‰æ ¼å¼çš„æµ‹è¯•ç»“æœ"""
        # æ”¶é›†å‹åŠ›æµ‹è¯•ç»“æœ
        stress_results = test_dir / 'stress' / 'results.json'
        if stress_results.exists():
            with open(stress_results, 'r') as f:
                self.test_results['stress_tests'] = json.load(f)
        
        # æ”¶é›†æ€§èƒ½æŒ‡æ ‡
        metrics_file = test_dir / 'metrics' / 'performance_metrics.json'
        if metrics_file.exists():
            with open(metrics_file, 'r') as f:
                self.test_results['metrics'] = json.load(f)
    
    def generate_summary_charts(self, output_dir: Path):
        """ç”Ÿæˆæ‘˜è¦å›¾è¡¨"""
        output_dir.mkdir(exist_ok=True)
        
        # 1. æµ‹è¯•ç»“æœé¥¼å›¾
        plt.figure(figsize=(8, 6))
        summary = self.test_results['summary']
        
        sizes = [summary['passed'], summary['failed'], summary['skipped']]
        labels = ['é€šè¿‡', 'å¤±è´¥', 'è·³è¿‡']
        colors = ['#4CAF50', '#F44336', '#FFC107']
        
        # è¿‡æ»¤æ‰0å€¼
        non_zero_indices = [i for i, size in enumerate(sizes) if size > 0]
        sizes = [sizes[i] for i in non_zero_indices]
        labels = [labels[i] for i in non_zero_indices]
        colors = [colors[i] for i in non_zero_indices]
        
        if sizes:  # ç¡®ä¿æœ‰æ•°æ®
            plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
            plt.title('æµ‹è¯•ç»“æœåˆ†å¸ƒ')
            plt.savefig(output_dir / 'test_results_pie.png')
            plt.close()
        
        # 2. å„ç±»æµ‹è¯•æ‰§è¡Œæ—¶é—´æŸ±çŠ¶å›¾
        test_categories = ['unit', 'integration', 'e2e', 'performance', 'stress', 'regression']
        durations = []
        
        for category in test_categories:
            tests = self.test_results.get(f'{category}_tests', [])
            total_duration = sum(t.get('time', 0) for t in tests if isinstance(t, dict))
            durations.append(total_duration)
        
        plt.figure(figsize=(10, 6))
        plt.bar(test_categories, durations, color='skyblue')
        plt.xlabel('æµ‹è¯•ç±»åˆ«')
        plt.ylabel('æ€»æ‰§è¡Œæ—¶é—´ (ç§’)')
        plt.title('å„ç±»æµ‹è¯•æ‰§è¡Œæ—¶é—´')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(output_dir / 'test_duration_bar.png')
        plt.close()
        
        # 3. è¦†ç›–ç‡å›¾è¡¨
        if self.test_results.get('coverage'):
            coverage_data = self.test_results['coverage']
            
            if 'totals' in coverage_data:
                plt.figure(figsize=(8, 6))
                
                metrics = ['statements', 'missing', 'excluded', 'branches']
                values = [
                    coverage_data['totals'].get('num_statements', 0),
                    coverage_data['totals'].get('missing_lines', 0),
                    coverage_data['totals'].get('excluded_lines', 0),
                    coverage_data['totals'].get('num_branches', 0)
                ]
                
                plt.bar(metrics, values, color=['green', 'red', 'yellow', 'blue'])
                plt.xlabel('æŒ‡æ ‡')
                plt.ylabel('æ•°é‡')
                plt.title('ä»£ç è¦†ç›–ç‡ç»Ÿè®¡')
                plt.tight_layout()
                plt.savefig(output_dir / 'coverage_stats.png')
                plt.close()
    
    def generate_html_report(self, output_path: Path):
        """ç”Ÿæˆ HTML æŠ¥å‘Š"""
        template_str = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>XianXia World Engine - NLP æ¨¡å—æµ‹è¯•æŠ¥å‘Š</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1, h2, h3 {
            color: #333;
        }
        .summary {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        .summary-card {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            text-align: center;
            border: 1px solid #e9ecef;
        }
        .summary-card h3 {
            margin: 0 0 10px 0;
            color: #666;
            font-size: 14px;
        }
        .summary-card .value {
            font-size: 36px;
            font-weight: bold;
            margin: 10px 0;
        }
        .passed { color: #4CAF50; }
        .failed { color: #F44336; }
        .skipped { color: #FFC107; }
        .chart-container {
            margin: 30px 0;
            text-align: center;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #f8f9fa;
            font-weight: bold;
        }
        tr:hover {
            background-color: #f5f5f5;
        }
        .status-passed {
            color: #4CAF50;
            font-weight: bold;
        }
        .status-failed {
            color: #F44336;
            font-weight: bold;
        }
        .status-skipped {
            color: #FFC107;
            font-weight: bold;
        }
        .section {
            margin: 40px 0;
        }
        .timestamp {
            color: #666;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>XianXia World Engine - NLP æ¨¡å—æµ‹è¯•æŠ¥å‘Š</h1>
        <p class="timestamp">ç”Ÿæˆæ—¶é—´: {{ summary.timestamp }}</p>
        
        <div class="summary">
            <div class="summary-card">
                <h3>æ€»æµ‹è¯•æ•°</h3>
                <div class="value">{{ summary.total_tests }}</div>
            </div>
            <div class="summary-card">
                <h3>é€šè¿‡</h3>
                <div class="value passed">{{ summary.passed }}</div>
            </div>
            <div class="summary-card">
                <h3>å¤±è´¥</h3>
                <div class="value failed">{{ summary.failed }}</div>
            </div>
            <div class="summary-card">
                <h3>è·³è¿‡</h3>
                <div class="value skipped">{{ summary.skipped }}</div>
            </div>
            <div class="summary-card">
                <h3>é€šè¿‡ç‡</h3>
                <div class="value">{{ "%.1f"|format(pass_rate) }}%</div>
            </div>
            <div class="summary-card">
                <h3>æ€»è€—æ—¶</h3>
                <div class="value">{{ "%.2f"|format(summary.duration) }}s</div>
            </div>
        </div>
        
        <div class="section">
            <h2>æµ‹è¯•ç»“æœåˆ†å¸ƒ</h2>
            <div class="chart-container">
                <img src="test_results_pie.png" alt="æµ‹è¯•ç»“æœé¥¼å›¾">
            </div>
        </div>
        
        <div class="section">
            <h2>å„ç±»æµ‹è¯•æ‰§è¡Œæ—¶é—´</h2>
            <div class="chart-container">
                <img src="test_duration_bar.png" alt="æ‰§è¡Œæ—¶é—´æŸ±çŠ¶å›¾">
            </div>
        </div>
        
        {% if coverage %}
        <div class="section">
            <h2>ä»£ç è¦†ç›–ç‡</h2>
            <div class="summary">
                <div class="summary-card">
                    <h3>è¡Œè¦†ç›–ç‡</h3>
                    <div class="value">{{ "%.1f"|format(coverage.percent_covered) }}%</div>
                </div>
                <div class="summary-card">
                    <h3>æ€»è¡Œæ•°</h3>
                    <div class="value">{{ coverage.num_statements }}</div>
                </div>
                <div class="summary-card">
                    <h3>å·²è¦†ç›–</h3>
                    <div class="value passed">{{ coverage.num_statements - coverage.missing_lines }}</div>
                </div>
                <div class="summary-card">
                    <h3>æœªè¦†ç›–</h3>
                    <div class="value failed">{{ coverage.missing_lines }}</div>
                </div>
            </div>
        </div>
        {% endif %}
        
        {% for test_type, tests in test_details.items() %}
        {% if tests %}
        <div class="section">
            <h2>{{ test_type }} è¯¦æƒ…</h2>
            <table>
                <thead>
                    <tr>
                        <th>æµ‹è¯•åç§°</th>
                        <th>çŠ¶æ€</th>
                        <th>è€—æ—¶</th>
                        <th>å¤‡æ³¨</th>
                    </tr>
                </thead>
                <tbody>
                    {% for test in tests[:20] %}
                    <tr>
                        <td>{{ test.name }}</td>
                        <td class="status-{{ test.status }}">{{ test.status.upper() }}</td>
                        <td>{{ "%.3f"|format(test.time) }}s</td>
                        <td>{{ test.message|default('', true) }}</td>
                    </tr>
                    {% endfor %}
                    {% if tests|length > 20 %}
                    <tr>
                        <td colspan="4" style="text-align: center; color: #666;">
                            ... è¿˜æœ‰ {{ tests|length - 20 }} ä¸ªæµ‹è¯•ç»“æœæœªæ˜¾ç¤º ...
                        </td>
                    </tr>
                    {% endif %}
                </tbody>
            </table>
        </div>
        {% endif %}
        {% endfor %}
        
        {% if performance_tests %}
        <div class="section">
            <h2>æ€§èƒ½æµ‹è¯•ç»“æœ</h2>
            <table>
                <thead>
                    <tr>
                        <th>æµ‹è¯•åç§°</th>
                        <th>å¹³å‡æ—¶é—´</th>
                        <th>æœ€å°æ—¶é—´</th>
                        <th>æœ€å¤§æ—¶é—´</th>
                        <th>æ ‡å‡†å·®</th>
                    </tr>
                </thead>
                <tbody>
                    {% for test in performance_tests[:10] %}
                    <tr>
                        <td>{{ test.name }}</td>
                        <td>{{ "%.3f"|format(test.stats.mean * 1000) }}ms</td>
                        <td>{{ "%.3f"|format(test.stats.min * 1000) }}ms</td>
                        <td>{{ "%.3f"|format(test.stats.max * 1000) }}ms</td>
                        <td>{{ "%.3f"|format(test.stats.stddev * 1000) }}ms</td>
                    </tr>
                    {% endfor %}
                </tbody>
            </table>
        </div>
        {% endif %}
        
        <div class="section">
            <h2>å»ºè®®å’Œæ”¹è¿›ç‚¹</h2>
            <ul>
                {% for recommendation in recommendations %}
                <li>{{ recommendation }}</li>
                {% endfor %}
            </ul>
        </div>
    </div>
</body>
</html>
        """
        
        # è®¡ç®—é€šè¿‡ç‡
        pass_rate = 0
        if self.test_results['summary']['total_tests'] > 0:
            pass_rate = (self.test_results['summary']['passed'] / 
                        self.test_results['summary']['total_tests'] * 100)
        
        # å‡†å¤‡æ¨¡æ¿æ•°æ®
        template_data = {
            'summary': self.test_results['summary'],
            'pass_rate': pass_rate,
            'coverage': self.test_results.get('coverage', {}).get('totals', {}),
            'test_details': {
                'å•å…ƒæµ‹è¯•': self.test_results['unit_tests'],
                'é›†æˆæµ‹è¯•': self.test_results['integration_tests'],
                'E2Eæµ‹è¯•': self.test_results['e2e_tests'],
                'å›å½’æµ‹è¯•': self.test_results['regression_tests']
            },
            'performance_tests': self.test_results['performance_tests'],
            'recommendations': self._generate_recommendations()
        }
        
        # æ¸²æŸ“æ¨¡æ¿
        template = Template(template_str)
        html_content = template.render(**template_data)
        
        # ä¿å­˜æŠ¥å‘Š
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        summary = self.test_results['summary']
        
        # åŸºäºæµ‹è¯•ç»“æœçš„å»ºè®®
        if summary['failed'] > 0:
            recommendations.append(f"âš ï¸ æœ‰ {summary['failed']} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·ä¼˜å…ˆä¿®å¤è¿™äº›é—®é¢˜")
        
        if summary['total_tests'] > 0:
            pass_rate = summary['passed'] / summary['total_tests'] * 100
            if pass_rate < 80:
                recommendations.append(f"âš ï¸ æµ‹è¯•é€šè¿‡ç‡ä»…ä¸º {pass_rate:.1f}%ï¼Œå»ºè®®æé«˜åˆ° 80% ä»¥ä¸Š")
        
        # åŸºäºè¦†ç›–ç‡çš„å»ºè®®
        coverage = self.test_results.get('coverage', {}).get('totals', {})
        if coverage:
            coverage_percent = coverage.get('percent_covered', 0)
            if coverage_percent < 80:
                recommendations.append(f"ğŸ“Š ä»£ç è¦†ç›–ç‡ä¸º {coverage_percent:.1f}%ï¼Œå»ºè®®æé«˜åˆ° 80% ä»¥ä¸Š")
        
        # åŸºäºæ€§èƒ½çš„å»ºè®®
        if self.test_results['performance_tests']:
            slow_tests = [t for t in self.test_results['performance_tests'] 
                         if isinstance(t, dict) and t.get('stats', {}).get('mean', 0) > 1.0]
            if slow_tests:
                recommendations.append(f"ğŸŒ æœ‰ {len(slow_tests)} ä¸ªæ€§èƒ½æµ‹è¯•è¶…è¿‡ 1 ç§’ï¼Œè€ƒè™‘ä¼˜åŒ–")
        
        # é€šç”¨å»ºè®®
        if not recommendations:
            recommendations.append("âœ… æµ‹è¯•ç»“æœè‰¯å¥½ï¼Œç»§ç»­ä¿æŒï¼")
        
        recommendations.extend([
            "ğŸ’¡ å®šæœŸè¿è¡Œå›å½’æµ‹è¯•ï¼Œç¡®ä¿ä¿®å¤çš„é—®é¢˜ä¸ä¼šé‡ç°",
            "ğŸ’¡ è€ƒè™‘æ·»åŠ æ›´å¤šè¾¹ç•Œæƒ…å†µçš„æµ‹è¯•ç”¨ä¾‹",
            "ğŸ’¡ ç›‘æ§ç”Ÿäº§ç¯å¢ƒçš„æ€§èƒ½æŒ‡æ ‡ï¼Œä¸æµ‹è¯•åŸºå‡†å¯¹æ¯”"
        ])
        
        return recommendations
    
    def generate_json_report(self, output_path: Path):
        """ç”Ÿæˆ JSON æ ¼å¼çš„æŠ¥å‘Š"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)
    
    def generate_markdown_report(self, output_path: Path):
        """ç”Ÿæˆ Markdown æ ¼å¼çš„æŠ¥å‘Š"""
        summary = self.test_results['summary']
        
        md_content = f"""# XianXia World Engine - NLP æ¨¡å—æµ‹è¯•æŠ¥å‘Š

ç”Ÿæˆæ—¶é—´: {summary['timestamp']}

## ğŸ“Š æµ‹è¯•æ‘˜è¦

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»æµ‹è¯•æ•° | {summary['total_tests']} |
| âœ… é€šè¿‡ | {summary['passed']} |
| âŒ å¤±è´¥ | {summary['failed']} |
| â­ï¸ è·³è¿‡ | {summary['skipped']} |
| é€šè¿‡ç‡ | {summary['passed'] / summary['total_tests'] * 100:.1f}% |
| æ€»è€—æ—¶ | {summary['duration']:.2f}ç§’ |

## ğŸ“ˆ å„ç±»æµ‹è¯•ç»“æœ

"""
        
        # æ·»åŠ å„ç±»æµ‹è¯•çš„ç»Ÿè®¡
        for test_type in ['unit', 'integration', 'e2e', 'performance', 'stress', 'regression']:
            tests = self.test_results.get(f'{test_type}_tests', [])
            if tests:
                passed = sum(1 for t in tests if t.get('status') == 'passed')
                failed = sum(1 for t in tests if t.get('status') == 'failed')
                
                md_content += f"""### {test_type.title()} Tests
- æ€»æ•°: {len(tests)}
- é€šè¿‡: {passed}
- å¤±è´¥: {failed}

"""
        
        # æ·»åŠ æ”¹è¿›å»ºè®®
        md_content += "## ğŸ’¡ æ”¹è¿›å»ºè®®\n\n"
        for rec in self._generate_recommendations():
            md_content += f"- {rec}\n"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(md_content)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š')
    parser.add_argument('--test-dir', type=str, default='tests', help='æµ‹è¯•ç›®å½•')
    parser.add_argument('--output', type=str, default='test-report.html', help='è¾“å‡ºæ–‡ä»¶')
    parser.add_argument('--format', choices=['html', 'json', 'markdown'], default='html', help='æŠ¥å‘Šæ ¼å¼')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
    generator = TestReportGenerator()
    
    # æ”¶é›†æµ‹è¯•ç»“æœ
    test_dir = Path(args.test_dir)
    if test_dir.exists():
        generator.collect_test_results(test_dir)
    
    # ç”Ÿæˆå›¾è¡¨
    output_dir = Path(args.output).parent
    generator.generate_summary_charts(output_dir)
    
    # ç”ŸæˆæŠ¥å‘Š
    output_path = Path(args.output)
    
    if args.format == 'html':
        generator.generate_html_report(output_path)
    elif args.format == 'json':
        generator.generate_json_report(output_path)
    elif args.format == 'markdown':
        generator.generate_markdown_report(output_path)
    
    print(f"æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")


if __name__ == "__main__":
    main()
