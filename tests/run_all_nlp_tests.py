#!/usr/bin/env python
"""
å¿«é€Ÿè¿è¡Œæ‰€æœ‰ NLP æ¨¡å—æµ‹è¯•çš„è„šæœ¬
ä½¿ç”¨æ–¹æ³•: python run_all_nlp_tests.py
"""

import subprocess
import sys
import time
from pathlib import Path
from datetime import datetime

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).resolve().parents[1]
TESTS_DIR = PROJECT_ROOT / "tests"


def run_command(cmd, description):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºç»“æœ"""
    print(f"\n{'='*60}")
    print(f"ğŸš€ {description}")
    print(f"å‘½ä»¤: {cmd}")
    print(f"{'='*60}")
    
    start_time = time.time()
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    duration = time.time() - start_time
    
    if result.returncode == 0:
        print(f"âœ… æˆåŠŸ (è€—æ—¶: {duration:.2f}ç§’)")
    else:
        print(f"âŒ å¤±è´¥ (è€—æ—¶: {duration:.2f}ç§’)")
        print(f"é”™è¯¯è¾“å‡º:\n{result.stderr}")
    
    return result.returncode == 0, duration


def main():
    """ä¸»å‡½æ•°"""
    print(f"XianXia World Engine - NLP æ¨¡å—æµ‹è¯•å¥—ä»¶")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æµ‹è¯•ç›®å½•: {TESTS_DIR}")
    
    # æµ‹è¯•é…ç½®
    tests = [
        {
            "name": "å•å…ƒæµ‹è¯•",
            "cmd": f"cd {PROJECT_ROOT} && pytest tests/unit/test_nlp_processor.py tests/unit/test_context_compressor.py tests/unit/test_async_utils.py tests/unit/test_prometheus_metrics.py -v",
            "required": True
        },
        {
            "name": "é›†æˆæµ‹è¯•",
            "cmd": f"cd {PROJECT_ROOT} && pytest tests/integration/test_nlp_integration.py -v",
            "required": True
        },
        {
            "name": "E2Eæµ‹è¯•ï¼ˆå¿«é€Ÿç‰ˆï¼‰",
            "cmd": f"cd {PROJECT_ROOT} && pytest tests/e2e/test_nlp_e2e.py::TestNLPEndToEnd::test_complete_user_journey -v",
            "required": True
        },
        {
            "name": "æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆç®€åŒ–ç‰ˆï¼‰",
            "cmd": f"cd {PROJECT_ROOT} && pytest tests/benchmark/test_nlp_performance.py::TestNLPPerformance::test_context_compression_ratio -v",
            "required": False
        },
        {
            "name": "å›å½’æµ‹è¯•",
            "cmd": f"cd {PROJECT_ROOT} && pytest tests/regression/test_nlp_regression.py -v -k 'not performance_regression'",
            "required": True
        },
        {
            "name": "ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š",
            "cmd": f"cd {PROJECT_ROOT} && python tests/generate_report.py --format markdown --output test-summary.md",
            "required": False
        }
    ]
    
    # è¿è¡Œæµ‹è¯•
    results = []
    total_duration = 0
    
    for test in tests:
        success, duration = run_command(test["cmd"], test["name"])
        results.append({
            "name": test["name"],
            "success": success,
            "duration": duration,
            "required": test["required"]
        })
        total_duration += duration
        
        # å¦‚æœå¿…éœ€çš„æµ‹è¯•å¤±è´¥ï¼Œè¯¢é—®æ˜¯å¦ç»§ç»­
        if test["required"] and not success:
            response = input("\nå¿…éœ€çš„æµ‹è¯•å¤±è´¥äº†ã€‚æ˜¯å¦ç»§ç»­è¿è¡Œå…¶ä»–æµ‹è¯•ï¼Ÿ(y/n): ")
            if response.lower() != 'y':
                break
    
    # æ˜¾ç¤ºæ€»ç»“
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print(f"{'='*60}")
    
    passed = sum(1 for r in results if r["success"])
    failed = sum(1 for r in results if not r["success"])
    
    for result in results:
        status = "âœ…" if result["success"] else "âŒ"
        print(f"{status} {result['name']:<30} ({result['duration']:.2f}ç§’)")
    
    print(f"\næ€»è®¡: {passed} é€šè¿‡, {failed} å¤±è´¥")
    print(f"æ€»è€—æ—¶: {total_duration:.2f}ç§’")
    
    # è¿”å›é€€å‡ºç 
    required_failed = any(r for r in results if r["required"] and not r["success"])
    return 1 if required_failed else 0


if __name__ == "__main__":
    sys.exit(main())
