#!/usr/bin/env python3
"""
XianXia World Engine - è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬
è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•ï¼Œå¹¶ç”ŸæˆæŠ¥å‘Šã€‚

åœ¨è¿è¡Œæ­¤è„šæœ¬å‰ï¼Œè¯·è®¾ç½®ç’°å¢ƒå˜é‡ `LLM_PROVIDER=mock`ï¼Œä¾‹å¦‚ï¼š

```bash
export LLM_PROVIDER=mock
python tests/run_all_tests.py
```

å¦‚éœ€çœŸå® LLM æµ‹è¯•ï¼Œå¯åœ¨ `.env` ä¸­é…ç½® API å¯†é’¥ã€‚
"""

import json
import os
import subprocess
import sys
import time

# é»˜è®¤ä½¿ç”¨ mock æä¾›å•†ï¼Œé™¤éå¤–éƒ¨å·²è®¾ç½®
if not os.getenv("LLM_PROVIDER"):
    os.environ["LLM_PROVIDER"] = "mock"
    print("âš ï¸ LLM_PROVIDER æœªè®¾ç½®ï¼Œå·²ä½¿ç”¨ 'mock' è¿›è¡Œæµ‹è¯•")
from datetime import datetime
from pathlib import Path

from xwe.utils.requests_helper import ensure_requests

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent


class TestRunner:
    def __init__(self):
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "unit_tests": {},
            "integration_tests": {},
            "main_scripts": {},
            "fixes_applied": [],
            "summary": {"total_tests": 0, "passed": 0, "failed": 0, "skipped": 0},
        }

    def run_pytest(self, test_path, test_type="unit"):
        """è¿è¡Œpytestæµ‹è¯•"""
        print(f"\n{'='*60}")
        print(f"è¿è¡Œ{test_type}æµ‹è¯•: {test_path}")
        print("=" * 60)

        # ç¡®ä¿æµ‹è¯•ç›®å½•å­˜åœ¨
        if not Path(test_path).exists():
            print(f"âŒ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {test_path}")
            return False

        try:
            # è¿è¡Œpytest
            env = os.environ.copy()
            result = subprocess.run(
                [sys.executable, "-m", "pytest", test_path, "-v", "--tb=short"],
                capture_output=True,
                text=True,
                cwd=PROJECT_ROOT,
                env=env,
            )

            # è§£æç»“æœ
            output = result.stdout + result.stderr
            print(output)

            # ç»Ÿè®¡æµ‹è¯•ç»“æœ
            passed = output.count(" PASSED")
            failed = output.count(" FAILED")
            skipped = output.count(" SKIPPED")

            test_result = {
                "path": test_path,
                "passed": passed,
                "failed": failed,
                "skipped": skipped,
                "return_code": result.returncode,
                "output": output[:1000],  # ä¿å­˜å‰1000å­—ç¬¦
            }

            if test_type == "unit":
                self.results["unit_tests"][test_path] = test_result
            else:
                self.results["integration_tests"][test_path] = test_result

            # æ›´æ–°æ€»è®¡
            self.results["summary"]["total_tests"] += passed + failed + skipped
            self.results["summary"]["passed"] += passed
            self.results["summary"]["failed"] += failed
            self.results["summary"]["skipped"] += skipped

            return result.returncode == 0

        except Exception as e:
            print(f"âŒ è¿è¡Œæµ‹è¯•å¤±è´¥: {e}")
            return False

    def run_main_script(self, script_path):
        """è¿è¡Œä¸»è¦è„šæœ¬è¿›è¡Œé›†æˆæµ‹è¯•"""
        print(f"\n{'='*60}")
        print(f"è¿è¡Œè„šæœ¬: {script_path}")
        print("=" * 60)

        if not Path(script_path).exists():
            print(f"âŒ è„šæœ¬ä¸å­˜åœ¨: {script_path}")
            return False

        try:
            # åˆ›å»ºæµ‹è¯•è¾“å…¥
            test_input = "æµ‹è¯•\n1\né€€å‡º\n"

            # è¿è¡Œè„šæœ¬ï¼ˆå¸¦è¶…æ—¶ï¼‰
            process = subprocess.Popen(
                [sys.executable, script_path],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                cwd=PROJECT_ROOT,
            )

            # å‘é€è¾“å…¥å¹¶ç­‰å¾…
            try:
                stdout, stderr = process.communicate(input=test_input, timeout=10)
                output = stdout + stderr
                success = process.returncode == 0 or "æ¸¸æˆå·²å¯åŠ¨" in output
            except subprocess.TimeoutExpired:
                process.kill()
                output = "è¶…æ—¶ï¼ˆè„šæœ¬æ­£å¸¸è¿è¡Œï¼‰"
                success = True  # è¶…æ—¶è¡¨ç¤ºè„šæœ¬åœ¨æŒç»­è¿è¡Œ

            print(output[:500])  # æ‰“å°å‰500å­—ç¬¦

            self.results["main_scripts"][script_path] = {
                "success": success,
                "output": output[:1000],
            }

            return success

        except Exception as e:
            print(f"âŒ è¿è¡Œè„šæœ¬å¤±è´¥: {e}")
            return False

    def check_and_fix_imports(self):
        """æ£€æŸ¥å¹¶ä¿®å¤å¯¼å…¥é—®é¢˜"""
        print("\nğŸ”§ æ£€æŸ¥å¯¼å…¥é—®é¢˜...")

        # æ£€æŸ¥å¸¸è§çš„å¯¼å…¥é—®é¢˜
        fixes_needed = []

        # æ£€æŸ¥NLPæ¨¡å—
        try:
            from xwe.core.nlp import NLPConfig, NLPProcessor

            print("âœ… NLPå¯¼å…¥æ­£å¸¸")
        except ImportError as e:
            print(f"âŒ NLPå¯¼å…¥é”™è¯¯: {e}")
            fixes_needed.append("NLPå¯¼å…¥")

        # æ£€æŸ¥Rollç³»ç»Ÿ
        try:
            from xwe.core.roll_system import CharacterRoller

            print("âœ… Rollç³»ç»Ÿå¯¼å…¥æ­£å¸¸")
        except ImportError as e:
            print(f"âŒ Rollç³»ç»Ÿå¯¼å…¥é”™è¯¯: {e}")
            fixes_needed.append("Rollç³»ç»Ÿå¯¼å…¥")

        return fixes_needed

    def fix_common_issues(self):
        """ä¿®å¤å¸¸è§é—®é¢˜"""
        print("\nğŸ”§ ä¿®å¤å¸¸è§é—®é¢˜...")

        # 1. ç¡®ä¿NLPConfigåœ¨__init__.pyä¸­å¯¼å‡º
        nlp_init_path = PROJECT_ROOT / "xwe/core/nlp/__init__.py"
        if nlp_init_path.exists():
            content = nlp_init_path.read_text()
            if "NLPConfig" not in content:
                print("ä¿®å¤: æ·»åŠ NLPConfigåˆ°nlp/__init__.py")
                new_content = content.replace(
                    "from .nlp_processor import NLPProcessor",
                    "from .nlp_processor import NLPProcessor, NLPConfig",
                )
                new_content = new_content.replace(
                    "__all__ = ['NLPProcessor'", "__all__ = ['NLPProcessor', 'NLPConfig'"
                )
                nlp_init_path.write_text(new_content)
                self.results["fixes_applied"].append("NLPConfigå¯¼å‡ºä¿®å¤")

    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report_path = PROJECT_ROOT / "test_report.json"
        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)

        # ç”ŸæˆMarkdownæŠ¥å‘Š
        md_report = f"""# XianXia World Engine - è‡ªåŠ¨åŒ–æµ‹è¯•æŠ¥å‘Š

ç”Ÿæˆæ—¶é—´: {self.results['timestamp']}

## ğŸ“Š æµ‹è¯•ç»Ÿè®¡

- **æ€»æµ‹è¯•æ•°**: {self.results['summary']['total_tests']}
- **é€šè¿‡**: {self.results['summary']['passed']} âœ…
- **å¤±è´¥**: {self.results['summary']['failed']} âŒ
- **è·³è¿‡**: {self.results['summary']['skipped']} â­ï¸

## ğŸ§ª å•å…ƒæµ‹è¯•ç»“æœ

"""
        for path, result in self.results["unit_tests"].items():
            status = "âœ…" if result["return_code"] == 0 else "âŒ"
            md_report += f"### {path} {status}\n"
            md_report += f"- é€šè¿‡: {result['passed']}\n"
            md_report += f"- å¤±è´¥: {result['failed']}\n"
            md_report += f"- è·³è¿‡: {result['skipped']}\n\n"

        md_report += "\n## ğŸ”§ é›†æˆæµ‹è¯•ç»“æœ\n\n"
        for path, result in self.results["integration_tests"].items():
            status = "âœ…" if result["return_code"] == 0 else "âŒ"
            md_report += f"### {path} {status}\n"
            md_report += f"- é€šè¿‡: {result['passed']}\n"
            md_report += f"- å¤±è´¥: {result['failed']}\n\n"

        md_report += "\n## ğŸ® ä¸»è„šæœ¬æµ‹è¯•ç»“æœ\n\n"
        for path, result in self.results["main_scripts"].items():
            status = "âœ…" if result["success"] else "âŒ"
            md_report += f"- {Path(path).name}: {status}\n"

        if self.results["fixes_applied"]:
            md_report += f"\n## ğŸ”§ è‡ªåŠ¨ä¿®å¤\n\n"
            for fix in self.results["fixes_applied"]:
                md_report += f"- {fix}\n"

        md_report_path = PROJECT_ROOT / "test_report.md"
        with open(md_report_path, "w", encoding="utf-8") as f:
            f.write(md_report)

        print(f"\nğŸ“‹ æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ:")
        print(f"  - JSON: {report_path}")
        print(f"  - Markdown: {md_report_path}")

        return md_report


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ XianXia World Engine - è‡ªåŠ¨åŒ–æµ‹è¯•")
    print("=" * 60)

    ensure_requests()

    runner = TestRunner()

    # 1. æ£€æŸ¥å¹¶ä¿®å¤å¸¸è§é—®é¢˜
    runner.fix_common_issues()

    # 2. è¿è¡Œå•å…ƒæµ‹è¯•
    print("\n\nğŸ§ª è¿è¡Œå•å…ƒæµ‹è¯•...")
    runner.run_pytest("tests/unit/", "unit")

    # 3. è¿è¡Œé›†æˆæµ‹è¯•
    print("\n\nğŸ”§ è¿è¡Œé›†æˆæµ‹è¯•...")
    runner.run_pytest("tests/integration/", "integration")
    runner.run_pytest("tests/", "integration")

    # 4. è¿è¡Œä¸»è¦è„šæœ¬
    print("\n\nğŸ® æµ‹è¯•ä¸»è¦è„šæœ¬...")
    scripts_to_test = [
        "verify_system.py",
        "scripts/test_roll.py",
        "scripts/test_nlp.py",
        "scripts/verify_project.py",
    ]

    for script in scripts_to_test:
        if Path(PROJECT_ROOT / script).exists():
            runner.run_main_script(script)

    # 5. ç”ŸæˆæŠ¥å‘Š
    report = runner.generate_report()
    print("\n\n" + report)

    # 6. æœ€ç»ˆç»“æœ
    if runner.results["summary"]["failed"] == 0:
        print("\n\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f"\n\nâŒ æœ‰ {runner.results['summary']['failed']} ä¸ªæµ‹è¯•å¤±è´¥")
        print("è¯·æŸ¥çœ‹test_report.mdäº†è§£è¯¦æƒ…")


if __name__ == "__main__":
    main()
