#!/usr/bin/env python3
"""
è¿è¡Œä¿®å¤åçš„æµ‹è¯•
"""
import subprocess
import sys
import os

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['USE_MOCK_LLM'] = 'true'
os.environ['ENABLE_PROMETHEUS'] = 'true'
os.environ['ENABLE_CONTEXT_COMPRESSION'] = 'true'

# æµ‹è¯•ç»„
TEST_GROUPS = {
    'nlp': [
        # "test_invalid_response_handling" å·²ç»è¢«æ›¿æ¢ä¸º "test_json_parsing_errors"
        'tests/unit/test_nlp_processor.py::TestNLPProcessor::test_json_parsing_errors',
    ],
    'context': [
        'tests/unit/test_context_compressor.py::TestContextCompressor::test_message_deduplication',
        'tests/unit/test_context_compressor.py::TestContextCompressor::test_incremental_compression',
        'tests/unit/test_context_compressor.py::TestCompressionStrategies::test_sliding_window_strategy',
        'tests/unit/test_context_compressor.py::TestCompressionStrategies::test_hybrid_strategy',
    ],
    'async': [
        'tests/unit/test_async_utils.py::TestAsyncRequestQueue::test_blocking_operations',
        'tests/unit/test_async_utils.py::TestRateLimiter::test_burst_handling',
        'tests/unit/test_async_utils.py::TestRateLimiter::test_thread_safe',
    ],
    'api': [
        'tests/regression/test_nlp_regression.py::TestNLPRegression::test_api_compatibility',
        'tests/e2e/test_nlp_e2e.py::TestNLPEndToEnd::test_complete_user_journey',
    ],
    'integration': [
        'tests/integration/test_nlp_integration.py::TestNLPIntegration::test_multi_module_coordination',
    ],
    'metrics': [
        # å®Œæ•´è¿è¡Œ metrics æµ‹è¯•æ–‡ä»¶ï¼Œå†…éƒ¨ä¼šåœ¨ç¼ºå°‘ä¾èµ–æ—¶è‡ªåŠ¨è·³è¿‡
        'tests/unit/test_prometheus_metrics.py',
    ]
}

def run_test_group(group_name):
    """è¿è¡ŒæŒ‡å®šçš„æµ‹è¯•ç»„"""
    if group_name not in TEST_GROUPS:
        print(f"æœªçŸ¥çš„æµ‹è¯•ç»„: {group_name}")
        print(f"å¯ç”¨çš„æµ‹è¯•ç»„: {', '.join(TEST_GROUPS.keys())}")
        return False
    
    tests = TEST_GROUPS[group_name]
    print(f"\nè¿è¡Œ {group_name} æµ‹è¯•ç»„ ({len(tests)} ä¸ªæµ‹è¯•)")
    print("=" * 80)
    
    failed_tests = []
    
    for test in tests:
        print(f"\nè¿è¡Œ: {test}")
        result = subprocess.run(
            ['pytest', test, '-v', '--tb=short'],
            capture_output=True,
            text=True
        )
        
        # pytest è¿”å›ç  5 è¡¨ç¤ºæ²¡æœ‰æ”¶é›†åˆ°æµ‹è¯•ï¼Œä¾‹å¦‚ä¾èµ–ç¼ºå¤±è¢«è·³è¿‡
        if result.returncode in (0, 4, 5):
            status_map = {0: "é€šè¿‡", 4: "è·³è¿‡", 5: "è·³è¿‡"}
            status = status_map.get(result.returncode, "é€šè¿‡")
            print(f"âœ“ {status}")
        else:
            print("âœ— å¤±è´¥")
            failed_tests.append(test)
            # æ˜¾ç¤ºé”™è¯¯æ‘˜è¦
            lines = result.stdout.split('\n') + result.stderr.split('\n')
            for line in lines:
                if 'FAILED' in line or 'ERROR' in line or 'assert' in line:
                    print(f"  {line}")
    
    if failed_tests:
        print(f"\nå¤±è´¥çš„æµ‹è¯• ({len(failed_tests)}):")
        for test in failed_tests:
            print(f"  - {test}")
        return False
    else:
        print(f"\nâœ“ æ‰€æœ‰ {group_name} æµ‹è¯•éƒ½é€šè¿‡äº†ï¼")
        return True

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1:
        # è¿è¡ŒæŒ‡å®šçš„æµ‹è¯•ç»„
        group = sys.argv[1]
        success = run_test_group(group)
        sys.exit(0 if success else 1)
    else:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•ç»„
        print("è¿è¡Œæ‰€æœ‰æµ‹è¯•ç»„...")
        all_passed = True
        
        for group in TEST_GROUPS:
            if not run_test_group(group):
                all_passed = False
        
        if all_passed:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼")
        else:
            print("\nâŒ æœ‰äº›æµ‹è¯•å¤±è´¥äº†ï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„è¾“å‡º")
        
        sys.exit(0 if all_passed else 1)

if __name__ == '__main__':
    main()
